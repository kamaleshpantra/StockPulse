{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kamaleshpantra/StockPulse/blob/main/Stockpulse_trend.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J-eRdTe8qoxO",
        "outputId": "daf58a9f-dd92-407f-9522-9e815bc2aa8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: apache-flink in /usr/local/lib/python3.11/dist-packages (2.0.0)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.11/dist-packages (from apache-flink) (0.10.9.7)\n",
            "Requirement already satisfied: python-dateutil<3,>=2.8.0 in /usr/local/lib/python3.11/dist-packages (from apache-flink) (2.8.2)\n",
            "Requirement already satisfied: apache-beam<=2.61.0,>=2.54.0 in /usr/local/lib/python3.11/dist-packages (from apache-flink) (2.61.0)\n",
            "Requirement already satisfied: cloudpickle>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from apache-flink) (2.2.1)\n",
            "Requirement already satisfied: avro>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from apache-flink) (1.12.0)\n",
            "Requirement already satisfied: pytz>=2018.3 in /usr/local/lib/python3.11/dist-packages (from apache-flink) (2025.2)\n",
            "Requirement already satisfied: fastavro!=1.8.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from apache-flink) (1.10.0)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from apache-flink) (2.32.3)\n",
            "Requirement already satisfied: protobuf>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from apache-flink) (5.29.4)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.11/dist-packages (from apache-flink) (2.0.2)\n",
            "Requirement already satisfied: pandas>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from apache-flink) (2.2.2)\n",
            "Requirement already satisfied: pyarrow>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from apache-flink) (16.1.0)\n",
            "Requirement already satisfied: pemja==0.4.1 in /usr/local/lib/python3.11/dist-packages (from apache-flink) (0.4.1)\n",
            "Requirement already satisfied: httplib2>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from apache-flink) (0.22.0)\n",
            "Requirement already satisfied: ruamel.yaml>=0.18.4 in /usr/local/lib/python3.11/dist-packages (from apache-flink) (0.18.10)\n",
            "Requirement already satisfied: apache-flink-libraries<2.0.1,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from apache-flink) (2.0.0)\n",
            "Requirement already satisfied: find-libpython in /usr/local/lib/python3.11/dist-packages (from pemja==0.4.1->apache-flink) (0.4.0)\n",
            "Requirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python3.11/dist-packages (from apache-beam<=2.61.0,>=2.54.0->apache-flink) (1.7)\n",
            "Requirement already satisfied: orjson<4,>=3.9.7 in /usr/local/lib/python3.11/dist-packages (from apache-beam<=2.61.0,>=2.54.0->apache-flink) (3.10.16)\n",
            "Requirement already satisfied: dill<0.3.2,>=0.3.1.1 in /usr/local/lib/python3.11/dist-packages (from apache-beam<=2.61.0,>=2.54.0->apache-flink) (0.3.1.1)\n",
            "Requirement already satisfied: fasteners<1.0,>=0.3 in /usr/local/lib/python3.11/dist-packages (from apache-beam<=2.61.0,>=2.54.0->apache-flink) (0.19)\n",
            "Requirement already satisfied: grpcio!=1.48.0,!=1.59.*,!=1.60.*,!=1.61.*,!=1.62.0,!=1.62.1,<1.66.0,<2,>=1.33.1 in /usr/local/lib/python3.11/dist-packages (from apache-beam<=2.61.0,>=2.54.0->apache-flink) (1.65.5)\n",
            "Requirement already satisfied: hdfs<3.0.0,>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from apache-beam<=2.61.0,>=2.54.0->apache-flink) (2.7.3)\n",
            "Requirement already satisfied: jsonschema<5.0.0,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from apache-beam<=2.61.0,>=2.54.0->apache-flink) (4.23.0)\n",
            "Requirement already satisfied: jsonpickle<4.0.0,>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from apache-beam<=2.61.0,>=2.54.0->apache-flink) (3.4.2)\n",
            "Requirement already satisfied: objsize<0.8.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from apache-beam<=2.61.0,>=2.54.0->apache-flink) (0.7.1)\n",
            "Requirement already satisfied: packaging>=22.0 in /usr/local/lib/python3.11/dist-packages (from apache-beam<=2.61.0,>=2.54.0->apache-flink) (24.2)\n",
            "Requirement already satisfied: pymongo<5.0.0,>=3.8.0 in /usr/local/lib/python3.11/dist-packages (from apache-beam<=2.61.0,>=2.54.0->apache-flink) (4.12.0)\n",
            "Requirement already satisfied: proto-plus<2,>=1.7.1 in /usr/local/lib/python3.11/dist-packages (from apache-beam<=2.61.0,>=2.54.0->apache-flink) (1.26.1)\n",
            "Requirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from apache-beam<=2.61.0,>=2.54.0->apache-flink) (1.4.2)\n",
            "Requirement already satisfied: redis<6,>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from apache-beam<=2.61.0,>=2.54.0->apache-flink) (5.2.1)\n",
            "Requirement already satisfied: regex>=2020.6.8 in /usr/local/lib/python3.11/dist-packages (from apache-beam<=2.61.0,>=2.54.0->apache-flink) (2024.11.6)\n",
            "Requirement already satisfied: sortedcontainers>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from apache-beam<=2.61.0,>=2.54.0->apache-flink) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.0 in /usr/local/lib/python3.11/dist-packages (from apache-beam<=2.61.0,>=2.54.0->apache-flink) (4.13.2)\n",
            "Requirement already satisfied: zstandard<1,>=0.18.0 in /usr/local/lib/python3.11/dist-packages (from apache-beam<=2.61.0,>=2.54.0->apache-flink) (0.23.0)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=3.12 in /usr/local/lib/python3.11/dist-packages (from apache-beam<=2.61.0,>=2.54.0->apache-flink) (6.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix<1 in /usr/local/lib/python3.11/dist-packages (from apache-beam<=2.61.0,>=2.54.0->apache-flink) (0.6)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2>=0.19.0->apache-flink) (3.2.3)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.3.0->apache-flink) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil<3,>=2.8.0->apache-flink) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->apache-flink) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->apache-flink) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->apache-flink) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->apache-flink) (2025.1.31)\n",
            "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in /usr/local/lib/python3.11/dist-packages (from ruamel.yaml>=0.18.4->apache-flink) (0.2.12)\n",
            "Requirement already satisfied: docopt in /usr/local/lib/python3.11/dist-packages (from hdfs<3.0.0,>=2.1.0->apache-beam<=2.61.0,>=2.54.0->apache-flink) (0.6.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam<=2.61.0,>=2.54.0->apache-flink) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam<=2.61.0,>=2.54.0->apache-flink) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam<=2.61.0,>=2.54.0->apache-flink) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam<=2.61.0,>=2.54.0->apache-flink) (0.24.0)\n",
            "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from pymongo<5.0.0,>=3.8.0->apache-beam<=2.61.0,>=2.54.0->apache-flink) (2.7.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install apache-flink"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sdzaXAaF-xPt",
        "outputId": "915e1b48-92bd-4302-994c-ca271bda36bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installed pyflink\n",
            "Installed praw==7.8.1\n",
            "Installed yfinance==0.2.54\n",
            "Installed streamlit==1.43.2\n",
            "Installed pyngrok==7.2.3\n",
            "Installed nltk==3.9.1\n",
            "Installed pandas==2.2.2\n",
            "Installed matplotlib==3.10.0\n",
            "Installed plotly==5.24.1\n",
            "Installed scikit-learn==1.6.1\n",
            "Installed tensorflow==2.18.0\n",
            "All dependencies installed successfully!\n"
          ]
        }
      ],
      "source": [
        "import subprocess\n",
        "import sys\n",
        "\n",
        "def install_packages():\n",
        "    packages = [\n",
        "        \"pyflink\",\n",
        "        \"praw==7.8.1\",\n",
        "        \"yfinance==0.2.54\",\n",
        "        \"streamlit==1.43.2\",\n",
        "        \"pyngrok==7.2.3\",\n",
        "        \"nltk==3.9.1\",\n",
        "        \"pandas==2.2.2\",\n",
        "        \"matplotlib==3.10.0\",\n",
        "        \"plotly==5.24.1\",\n",
        "        \"scikit-learn==1.6.1\",\n",
        "        \"tensorflow==2.18.0\"\n",
        "    ]\n",
        "    for pkg in packages:\n",
        "        try:\n",
        "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", pkg])\n",
        "            print(f\"Installed {pkg}\")\n",
        "        except subprocess.CalledProcessError as e:\n",
        "            print(f\"Failed to install {pkg}: {e}\")\n",
        "            raise\n",
        "\n",
        "install_packages()\n",
        "print(\"All dependencies installed successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8yvwX_ICi_ED",
        "outputId": "48a2404c-71c8-48f6-8600-742003d006bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reddit API initialized\n",
            "Setup complete!\n",
            "2024-04-19 2025-04-19\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import logging\n",
        "import nltk\n",
        "import praw\n",
        "import yfinance as yf\n",
        "from pyflink.table import EnvironmentSettings, TableEnvironment, StreamTableEnvironment\n",
        "from pyflink.table.udf import udf\n",
        "from pyflink.datastream import StreamExecutionEnvironment\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "import pandas as pd\n",
        "import json\n",
        "from datetime import datetime, timedelta\n",
        "import time\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import plotly.graph_objects as go\n",
        "import streamlit as st\n",
        "from pyngrok import ngrok\n",
        "from google.colab import userdata\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    filename=\"/content/stock_predict.log\",\n",
        "    format=\"%(asctime)s - %(levelname)s - %(message)s\"\n",
        ")\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Download NLTK data\n",
        "nltk.download('vader_lexicon', quiet=True)\n",
        "\n",
        "# Define sector\n",
        "sectors = {\"Technology\": [\"AAPL\", \"MSFT\", \"GOOGL\", \"TSLA\"]}\n",
        "\n",
        "# Initialize Reddit API with Colab Secrets\n",
        "try:\n",
        "    client_id = userdata.get(\"REDDIT_CLIENT_ID\")\n",
        "    client_secret = userdata.get(\"REDDIT_CLIENT_SECRET\")\n",
        "    user_agent = userdata.get(\"REDDIT_USER_AGENT\") or \"StockSentiment/1.0\"\n",
        "    if not all([client_id, client_secret, user_agent]):\n",
        "        raise ValueError(\"One or more Reddit credentials are missing\")\n",
        "    reddit = praw.Reddit(\n",
        "        client_id=client_id,\n",
        "        client_secret=client_secret,\n",
        "        user_agent=user_agent,\n",
        "        read_only=True,\n",
        "        requestor_kwargs={\"timeout\": 10}\n",
        "    )\n",
        "    limits = reddit.auth.limits\n",
        "    logger.info(\"Reddit API initialized. Rate limit remaining: %s\", limits.get(\"remaining\", \"unknown\"))\n",
        "    print(\"Reddit API initialized\")\n",
        "except Exception as e:\n",
        "    logger.error(f\"Failed to initialize Reddit API: {e}\")\n",
        "    raise ValueError(\n",
        "        \"Reddit API setup failed. Ensure REDDIT_CLIENT_ID, REDDIT_CLIENT_SECRET, \"\n",
        "        \"and REDDIT_USER_AGENT are set in Colab Secrets.\"\n",
        "    )\n",
        "\n",
        "# Initialize VADER\n",
        "sid = SentimentIntensityAnalyzer()\n",
        "\n",
        "# Define date range\n",
        "end_date = datetime.now().date()\n",
        "start_date = end_date - timedelta(days=365)\n",
        "\n",
        "# Helper for trading days\n",
        "def next_trading_day(date):\n",
        "    \"\"\"Map to next trading day (skip weekends).\"\"\"\n",
        "    date = pd.to_datetime(date)\n",
        "    while date.weekday() >= 5:  # Saturday or Sunday\n",
        "        date += timedelta(days=1)\n",
        "    return date.date()\n",
        "\n",
        "logger.info(\"Setup complete\")\n",
        "print(\"Setup complete!\")\n",
        "print(start_date,end_date)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HxWSbZe3NOtj",
        "outputId": "3f9dfc38-2798-4bc0-874f-3ba80d383ce4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cached Reddit data: /content/reddit_Technology_large.jsonl\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import logging\n",
        "import json\n",
        "import time\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "def fetch_large_reddit(sector, subreddits=[\"wallstreetbets\", \"stocks\", \"investing\"], limit_per_query=500):\n",
        "    \"\"\"\n",
        "    Fetch Reddit posts for sector companies within date range, ensuring relevance.\n",
        "\n",
        "    Args:\n",
        "        sector (str): Sector name (e.g., 'Technology').\n",
        "        subreddits (list): Subreddits to search.\n",
        "        limit_per_query (int): Max posts per subreddit.\n",
        "\n",
        "    Returns:\n",
        "        str: Path to JSONL file.\n",
        "    \"\"\"\n",
        "    logger.info(f\"Fetching Reddit data for {sector}\")\n",
        "    filename = f\"/content/reddit_{sector}_large.jsonl\"\n",
        "\n",
        "    if os.path.exists(filename):\n",
        "        logger.info(f\"Using cached Reddit data: {filename}\")\n",
        "        print(f\"Using cached Reddit data: {filename}\")\n",
        "        return filename\n",
        "\n",
        "    companies = sectors[sector]\n",
        "    all_posts = []\n",
        "    start_timestamp = datetime.combine(start_date, datetime.min.time()).timestamp()\n",
        "    end_timestamp = datetime.combine(end_date + timedelta(days=1), datetime.min.time()).timestamp() - 1\n",
        "\n",
        "    for company in companies:\n",
        "        for subreddit in subreddits:\n",
        "            for attempt in range(3):\n",
        "                try:\n",
        "                    logger.info(f\"Attempt {attempt+1}: Fetching {company} from r/{subreddit}\")\n",
        "                    print(f\"Fetching {company} from r/{subreddit} (Attempt {attempt+1})...\")\n",
        "                    submissions = reddit.subreddit(subreddit).search(\n",
        "                        query=company, sort=\"new\", limit=limit_per_query, time_filter=\"year\"\n",
        "                    )\n",
        "                    post_count = 0\n",
        "                    for submission in submissions:\n",
        "                        if start_timestamp <= submission.created_utc <= end_timestamp:\n",
        "                            text = submission.title + \" \" + (submission.selftext or \"\")\n",
        "                            if company.lower() in text.lower():\n",
        "                                post = {\n",
        "                                    \"company\": company,\n",
        "                                    \"text\": text,\n",
        "                                    \"timestamp\": submission.created_utc,\n",
        "                                    \"subreddit\": subreddit\n",
        "                                }\n",
        "                                all_posts.append(post)\n",
        "                                post_count += 1\n",
        "                    logger.info(f\"Fetched {post_count} posts for {company} in r/{subreddit}\")\n",
        "                    print(f\"Fetched {post_count} posts for {company} in r/{subreddit}\")\n",
        "                    break  # Success, move to next subreddit\n",
        "                except Exception as e:\n",
        "                    logger.error(f\"Attempt {attempt+1} failed for {company} in {subreddit}: {e}\")\n",
        "                    print(f\"Error for {company} in {subreddit}: {e}\")\n",
        "                    if attempt < 2:\n",
        "                        time.sleep(5)  # Wait before retry\n",
        "                    continue\n",
        "                finally:\n",
        "                    time.sleep(2)  # Rate limit delay\n",
        "\n",
        "    if not all_posts:\n",
        "        logger.warning(f\"No Reddit posts fetched for {sector}\")\n",
        "        print(f\"No Reddit posts fetched for {sector}\")\n",
        "        return filename\n",
        "\n",
        "    with open(filename, \"w\") as f:\n",
        "        for post in all_posts:\n",
        "            f.write(json.dumps(post) + \"\\n\")\n",
        "\n",
        "    logger.info(f\"Saved {len(all_posts)} posts to {filename}\")\n",
        "    print(f\"Saved {len(all_posts)} posts to {filename}\")\n",
        "    return filename\n",
        "\n",
        "sector = \"Technology\"\n",
        "reddit_file = fetch_large_reddit(sector)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x1JB7sRf6PjA",
        "outputId": "dcd8bb80-aa0c-41d2-e35b-1c1c55f40fe1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cached stock data for AAPL\n",
            "Using cached stock data for MSFT\n",
            "Using cached stock data for GOOGL\n",
            "Using cached stock data for TSLA\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import logging\n",
        "import yfinance as yf\n",
        "\n",
        "def fetch_stock_data(sector, cache_dir=\"/content/data\"):\n",
        "    \"\"\"Fetch stock prices for sector companies within date range.\"\"\"\n",
        "    logger.info(f\"Fetching stock data for {sector}\")\n",
        "    os.makedirs(cache_dir, exist_ok=True)\n",
        "    companies = sectors[sector]\n",
        "\n",
        "    for company in companies:\n",
        "        cache_file = f\"{cache_dir}/stock_{company}.csv\"\n",
        "        if os.path.exists(cache_file):\n",
        "            logger.info(f\"Using cached stock data for {company}\")\n",
        "            print(f\"Using cached stock data for {company}\")\n",
        "            continue\n",
        "        try:\n",
        "            print(f\"Fetching stock data for {company}...\")\n",
        "            stock = yf.Ticker(company)\n",
        "            hist = stock.history(start=start_date, end=end_date + timedelta(days=1), interval=\"1d\")\n",
        "            if hist.empty:\n",
        "                logger.warning(f\"No stock data for {company}\")\n",
        "                print(f\"No stock data for {company}\")\n",
        "                continue\n",
        "            hist = hist.reset_index()[[\"Date\", \"Open\", \"Close\", \"High\", \"Low\", \"Volume\"]]\n",
        "            hist[\"Date\"] = pd.to_datetime(hist[\"Date\"]).dt.date\n",
        "            hist.to_csv(cache_file, index=False)\n",
        "            logger.info(f\"Saved {len(hist)} days for {company} to {cache_file}\")\n",
        "            print(f\"Saved {len(hist)} days for {company}\")\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error fetching stock data for {company}: {e}\")\n",
        "            print(f\"Error for {company}: {e}\")\n",
        "            continue\n",
        "\n",
        "fetch_stock_data(sector=\"Technology\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QNhiJ50c596v",
        "outputId": "194c0f28-5492-46fe-8c97-299e795581c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed Reddit posts for Technology\n",
            "Processed stock data for AAPL\n",
            "Processed stock data for MSFT\n",
            "Processed stock data for GOOGL\n",
            "Processed stock data for TSLA\n"
          ]
        }
      ],
      "source": [
        "from pyflink.table import EnvironmentSettings, TableEnvironment\n",
        "from pyflink.table.udf import udf\n",
        "import pandas as pd\n",
        "import logging\n",
        "import os\n",
        "import json\n",
        "\n",
        "def preprocess_reddit(sector):\n",
        "    \"\"\"Process Reddit posts with Flink to compute daily sentiment in batch mode.\"\"\"\n",
        "    logger.info(f\"Preprocessing Reddit data for {sector}\")\n",
        "    env_settings = EnvironmentSettings.in_batch_mode()\n",
        "    t_env = TableEnvironment.create(env_settings)\n",
        "\n",
        "    @udf(result_type=\"MAP<STRING, STRING>\")\n",
        "    def parse_json(line):\n",
        "        \"\"\"Parse JSON string into a map.\"\"\"\n",
        "        try:\n",
        "            data = json.loads(line)\n",
        "            return {k: str(v) for k, v in data.items()}\n",
        "        except:\n",
        "            return {}\n",
        "\n",
        "    @udf(result_type=\"FLOAT\")\n",
        "    def get_vader_sentiment(text):\n",
        "        try:\n",
        "            return sid.polarity_scores(text or \"\")[\"compound\"]\n",
        "        except:\n",
        "            return 0.0\n",
        "\n",
        "    @udf(result_type=\"STRING\")\n",
        "    def to_trading_date(timestamp):\n",
        "        try:\n",
        "            date = pd.to_datetime(float(timestamp), unit=\"s\")\n",
        "            return str(next_trading_day(date))\n",
        "        except:\n",
        "            return str(end_date)\n",
        "\n",
        "    t_env.create_temporary_function(\"parse_json\", parse_json)\n",
        "    t_env.create_temporary_function(\"get_vader_sentiment\", get_vader_sentiment)\n",
        "    t_env.create_temporary_function(\"to_trading_date\", to_trading_date)\n",
        "\n",
        "    reddit_file = f\"/content/reddit_{sector}_large.jsonl\"\n",
        "    if not os.path.exists(reddit_file):\n",
        "        logger.warning(f\"No Reddit data for {sector}\")\n",
        "        print(f\"No Reddit data for {sector}\")\n",
        "        return\n",
        "\n",
        "    t_env.execute_sql(\"\"\"\n",
        "        CREATE TABLE reddit_source (\n",
        "            line STRING\n",
        "        ) WITH (\n",
        "            'connector' = 'filesystem',\n",
        "            'path' = 'file://%s',\n",
        "            'format' = 'raw'\n",
        "        )\n",
        "    \"\"\" % reddit_file)\n",
        "\n",
        "    t_env.execute_sql(\"\"\"\n",
        "        CREATE TEMPORARY VIEW parsed_reddit AS\n",
        "        SELECT\n",
        "            parsed['company'] AS company,\n",
        "            to_trading_date(parsed['timestamp']) AS trading_date,\n",
        "            get_vader_sentiment(parsed['text']) AS sentiment_score\n",
        "        FROM (\n",
        "            SELECT parse_json(line) AS parsed\n",
        "            FROM reddit_source\n",
        "            WHERE line IS NOT NULL\n",
        "        ) t\n",
        "        WHERE parsed['company'] IS NOT NULL AND parsed['timestamp'] IS NOT NULL\n",
        "    \"\"\")\n",
        "\n",
        "    agg_table = t_env.sql_query(\"\"\"\n",
        "        SELECT\n",
        "            company,\n",
        "            trading_date,\n",
        "            AVG(sentiment_score) AS avg_sentiment,\n",
        "            COUNT(*) AS post_count\n",
        "        FROM parsed_reddit\n",
        "        GROUP BY company, trading_date\n",
        "    \"\"\")\n",
        "\n",
        "    sink_file = f\"/content/daily_sentiment_{sector}.csv\"\n",
        "    t_env.execute_sql(\"\"\"\n",
        "        CREATE TABLE sentiment_sink (\n",
        "            company STRING,\n",
        "            trading_date STRING,\n",
        "            avg_sentiment FLOAT,\n",
        "            post_count BIGINT\n",
        "        ) WITH (\n",
        "            'connector' = 'filesystem',\n",
        "            'path' = 'file://%s',\n",
        "            'format' = 'csv'\n",
        "        )\n",
        "    \"\"\" % sink_file)\n",
        "\n",
        "    agg_table.execute_insert(\"sentiment_sink\").wait()\n",
        "    logger.info(f\"Processed Reddit posts to {sink_file}\")\n",
        "    print(f\"Processed Reddit posts for {sector}\")\n",
        "\n",
        "def preprocess_stock(sector):\n",
        "    \"\"\"Process stock data with Flink for trends.\"\"\"\n",
        "    logger.info(f\"Preprocessing stock data for {sector}\")\n",
        "    env_settings = EnvironmentSettings.in_batch_mode()\n",
        "    t_env = TableEnvironment.create(env_settings)\n",
        "\n",
        "    companies = sectors[sector]\n",
        "    for company in companies:\n",
        "        cache_file = f\"/content/data/stock_{company}.csv\"\n",
        "        if not os.path.exists(cache_file):\n",
        "            logger.warning(f\"Stock data missing for {company}\")\n",
        "            print(f\"Stock data missing for {company}\")\n",
        "            continue\n",
        "\n",
        "        source_table = f\"stock_source_{company}\"\n",
        "        t_env.execute_sql(\"\"\"\n",
        "            CREATE TABLE %s (\n",
        "                `Date` STRING,\n",
        "                `Open` DOUBLE,\n",
        "                `Close` DOUBLE,\n",
        "                `High` DOUBLE,\n",
        "                `Low` DOUBLE,\n",
        "                `Volume` BIGINT\n",
        "            ) WITH (\n",
        "                'connector' = 'filesystem',\n",
        "                'path' = 'file://%s',\n",
        "                'format' = 'csv',\n",
        "                'csv.ignore-parse-errors' = 'true'\n",
        "            )\n",
        "        \"\"\" % (source_table, cache_file))\n",
        "\n",
        "        table = t_env.sql_query(\"\"\"\n",
        "            SELECT\n",
        "                `Date` AS `date`,\n",
        "                `Close` AS `close`,\n",
        "                CASE\n",
        "                    WHEN LEAD(`Close`) OVER (ORDER BY `Date`) > `Close` THEN 1\n",
        "                    ELSE 0\n",
        "                END AS `trend`\n",
        "            FROM %s\n",
        "            WHERE `Date` IS NOT NULL\n",
        "        \"\"\" % source_table)\n",
        "\n",
        "        sink_file = f\"/content/processed_stock_{company}.csv\"\n",
        "        sink_table = f\"stock_sink_{company}\"\n",
        "        t_env.execute_sql(\"\"\"\n",
        "            CREATE TABLE %s (\n",
        "                `date` STRING,\n",
        "                `close` DOUBLE,\n",
        "                `trend` INT\n",
        "            ) WITH (\n",
        "                'connector' = 'filesystem',\n",
        "                'path' = 'file://%s',\n",
        "                'format' = 'csv'\n",
        "            )\n",
        "        \"\"\" % (sink_table, sink_file))\n",
        "\n",
        "        table.execute_insert(sink_table).wait()\n",
        "        logger.info(f\"Processed stock data to {sink_file}\")\n",
        "        print(f\"Processed stock data for {company}\")\n",
        "\n",
        "preprocess_reddit(sector=\"Technology\")\n",
        "preprocess_stock(sector=\"Technology\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Pme1KP8_ifN",
        "outputId": "2ffec0f4-8a12-4927-8d97-7a7eb34282e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded sentiment data: 716 rows\n",
            "Sentiment columns: ['company', 'trading_date', 'avg_sentiment', 'post_count']\n",
            "Sentiment sample:\n",
            "  company trading_date  avg_sentiment  post_count\n",
            "0    AAPL   2025-04-17       0.204750           2\n",
            "1    AAPL   2025-04-09       0.106567           6\n",
            "2    AAPL   2025-04-03       0.450271           7\n",
            "3    AAPL   2025-04-01       0.593433           3\n",
            "4    AAPL   2025-03-20       0.036550           2\n",
            "Unique companies: ['AAPL' 'MSFT' 'GOOGL' 'TSLA']\n",
            "Loaded stock data for AAPL: 251 rows\n",
            "Stock columns for AAPL: ['date', 'close', 'trend']\n",
            "Stock sample for AAPL:\n",
            "         date       close  trend\n",
            "0  2024-04-19  164.224564      1\n",
            "1  2024-04-22  165.060593      1\n",
            "2  2024-04-23  166.115616      1\n",
            "3  2024-04-24  168.225662      1\n",
            "4  2024-04-25  169.091568      0\n",
            "Merged data for AAPL: 251 rows\n",
            "Created 191 sequences for AAPL\n",
            "Loaded stock data for MSFT: 251 rows\n",
            "Stock columns for MSFT: ['date', 'close', 'trend']\n",
            "Stock sample for MSFT:\n",
            "         date       close  trend\n",
            "0  2024-04-19  396.095947      1\n",
            "1  2024-04-22  397.921997      1\n",
            "2  2024-04-23  404.481934      1\n",
            "3  2024-04-24  405.960632      0\n",
            "4  2024-04-25  396.016571      1\n",
            "Merged data for MSFT: 251 rows\n",
            "Created 191 sequences for MSFT\n",
            "Loaded stock data for GOOGL: 251 rows\n",
            "Stock columns for GOOGL: ['date', 'close', 'trend']\n",
            "Stock sample for GOOGL:\n",
            "         date       close  trend\n",
            "0  2024-04-19  153.356796      1\n",
            "1  2024-04-22  155.536392      1\n",
            "2  2024-04-23  157.506973      1\n",
            "3  2024-04-24  158.372833      0\n",
            "4  2024-04-25  155.257721      1\n",
            "Merged data for GOOGL: 251 rows\n",
            "Created 191 sequences for GOOGL\n",
            "Loaded stock data for TSLA: 251 rows\n",
            "Stock columns for TSLA: ['date', 'close', 'trend']\n",
            "Stock sample for TSLA:\n",
            "         date       close  trend\n",
            "0  2024-04-19  147.050003      0\n",
            "1  2024-04-22  142.050003      1\n",
            "2  2024-04-23  144.679993      1\n",
            "3  2024-04-24  162.130005      1\n",
            "4  2024-04-25  170.179993      0\n",
            "Merged data for TSLA: 251 rows\n",
            "Created 191 sequences for TSLA\n",
            "Total sequences prepared: 764\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import logging\n",
        "import os\n",
        "import glob\n",
        "\n",
        "# Assuming logger, sectors from Segment 2\n",
        "logger.info(\"Starting LSTM data preparation\")\n",
        "\n",
        "def prepare_lstm_data(sector, sequence_length=60):\n",
        "    \"\"\"Prepare sequences for LSTM from sentiment and stock data.\"\"\"\n",
        "    logger.info(f\"Preparing LSTM data for {sector}\")\n",
        "\n",
        "    # Find sentiment part file\n",
        "    sentiment_dir = f\"/content/daily_sentiment_{sector}.csv\"\n",
        "    sentiment_files = glob.glob(f\"{sentiment_dir}/part-*\")\n",
        "    if not sentiment_files:\n",
        "        logger.error(f\"No part files found in {sentiment_dir}\")\n",
        "        print(f\"No part files found in {sentiment_dir}\")\n",
        "        return []\n",
        "\n",
        "    sentiment_part_file = sentiment_files[0]  # Take first part file\n",
        "    if not os.path.isfile(sentiment_part_file):\n",
        "        logger.error(f\"Sentiment part file is not a file: {sentiment_part_file}\")\n",
        "        print(f\"Sentiment part file is not a file: {sentiment_part_file}\")\n",
        "        return []\n",
        "\n",
        "    # Read sentiment data with explicit column names\n",
        "    try:\n",
        "        sentiment_df = pd.read_csv(\n",
        "            sentiment_part_file,\n",
        "            names=['company', 'trading_date', 'avg_sentiment', 'post_count'],\n",
        "            header=None\n",
        "        )\n",
        "        logger.info(f\"Loaded sentiment data: {len(sentiment_df)} rows\")\n",
        "        print(f\"Loaded sentiment data: {len(sentiment_df)} rows\")\n",
        "        print(f\"Sentiment columns: {list(sentiment_df.columns)}\")\n",
        "        print(\"Sentiment sample:\")\n",
        "        print(sentiment_df.head().to_string())\n",
        "        unique_companies = sentiment_df['company'].unique()\n",
        "        print(f\"Unique companies: {unique_companies}\")\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Failed to read sentiment part file {sentiment_part_file}: {e}\")\n",
        "        print(f\"Failed to read sentiment part file: {e}\")\n",
        "        return []\n",
        "\n",
        "    # Validate sentiment columns\n",
        "    required_cols = ['company', 'trading_date', 'avg_sentiment', 'post_count']\n",
        "    missing_cols = [col for col in required_cols if col not in sentiment_df.columns]\n",
        "    if missing_cols:\n",
        "        logger.error(f\"Missing required columns in sentiment data: {missing_cols}\")\n",
        "        print(f\"Missing required columns in sentiment data: {missing_cols}\")\n",
        "        return []\n",
        "\n",
        "    companies = sectors[sector]\n",
        "    sequences = []\n",
        "    scaler = MinMaxScaler()\n",
        "\n",
        "    for company in companies:\n",
        "        # Find stock part file\n",
        "        stock_dir = f\"/content/processed_stock_{company}.csv\"\n",
        "        stock_files = glob.glob(f\"{stock_dir}/part-*\")\n",
        "        if not stock_files:\n",
        "            logger.warning(f\"No part files found in {stock_dir}\")\n",
        "            print(f\"No part files found for {company}\")\n",
        "            continue\n",
        "\n",
        "        stock_part_file = stock_files[0]  # Take first part file\n",
        "        if not os.path.isfile(stock_part_file):\n",
        "            logger.warning(f\"Stock part file is not a file: {stock_part_file}\")\n",
        "            print(f\"Stock part file is not a file for {company}\")\n",
        "            continue\n",
        "\n",
        "        # Read stock data with explicit column names\n",
        "        try:\n",
        "            stock_df = pd.read_csv(\n",
        "                stock_part_file,\n",
        "                names=['date', 'close', 'trend'],\n",
        "                header=None\n",
        "            )\n",
        "            logger.info(f\"Loaded stock data for {company}: {len(stock_df)} rows\")\n",
        "            print(f\"Loaded stock data for {company}: {len(stock_df)} rows\")\n",
        "            print(f\"Stock columns for {company}: {list(stock_df.columns)}\")\n",
        "            print(f\"Stock sample for {company}:\")\n",
        "            print(stock_df.head().to_string())\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Failed to read stock part file {stock_part_file}: {e}\")\n",
        "            print(f\"Failed to read stock part file for {company}: {e}\")\n",
        "            continue\n",
        "\n",
        "        # Validate stock columns\n",
        "        required_stock_cols = ['date', 'close', 'trend']\n",
        "        missing_stock_cols = [col for col in required_stock_cols if col not in stock_df.columns]\n",
        "        if missing_stock_cols:\n",
        "            logger.error(f\"Missing required columns in stock data for {company}: {missing_stock_cols}\")\n",
        "            print(f\"Missing required columns in stock data for {company}: {missing_stock_cols}\")\n",
        "            continue\n",
        "\n",
        "        # Merge data\n",
        "        try:\n",
        "            company_sentiment = sentiment_df[sentiment_df['company'] == company][\n",
        "                ['trading_date', 'avg_sentiment', 'post_count']\n",
        "            ]\n",
        "            merged_df = stock_df.merge(\n",
        "                company_sentiment,\n",
        "                left_on='date',\n",
        "                right_on='trading_date',\n",
        "                how='left'\n",
        "            )\n",
        "            merged_df['avg_sentiment'] = merged_df['avg_sentiment'].fillna(0.0)\n",
        "            merged_df['post_count'] = merged_df['post_count'].fillna(0)\n",
        "            merged_df = merged_df.drop(columns=['trading_date'], errors='ignore')\n",
        "            logger.info(f\"Merged data for {company}: {len(merged_df)} rows\")\n",
        "            print(f\"Merged data for {company}: {len(merged_df)} rows\")\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Failed to merge data for {company}: {e}\")\n",
        "            print(f\"Failed to merge data for {company}: {e}\")\n",
        "            continue\n",
        "\n",
        "        # Prepare features and target\n",
        "        try:\n",
        "            features = merged_df[['close', 'avg_sentiment', 'post_count']].values\n",
        "            target = merged_df['trend'].values\n",
        "\n",
        "            if len(features) > 0:\n",
        "                scaled_features = scaler.fit_transform(features)\n",
        "            else:\n",
        "                logger.warning(f\"No features for {company}\")\n",
        "                print(f\"No features for {company}\")\n",
        "                continue\n",
        "\n",
        "            X, y = [], []\n",
        "            for i in range(len(scaled_features) - sequence_length):\n",
        "                X.append(scaled_features[i:i + sequence_length])\n",
        "                y.append(target[i + sequence_length])\n",
        "\n",
        "            if X:\n",
        "                sequences.append((company, np.array(X), np.array(y)))\n",
        "                logger.info(f\"Created {len(X)} sequences for {company}\")\n",
        "                print(f\"Created {len(X)} sequences for {company}\")\n",
        "            else:\n",
        "                logger.warning(f\"No sequences for {company}\")\n",
        "                print(f\"No sequences for {company}\")\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Failed to create sequences for {company}: {e}\")\n",
        "            print(f\"Failed to create sequences for {company}: {e}\")\n",
        "\n",
        "    total_sequences = sum(len(X) for _, X, _ in sequences)\n",
        "    logger.info(f\"Total sequences prepared: {total_sequences}\")\n",
        "    print(f\"Total sequences prepared: {total_sequences}\")\n",
        "    return sequences\n",
        "\n",
        "# Run for Technology sector\n",
        "lstm_data = prepare_lstm_data(\"Technology\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZkQM4Et_DrQK",
        "outputId": "e4f2b0e8-7780-4406-ec2b-fa94b4e6d739"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training LSTM for AAPL\n",
            "AAPL - Train: (152, 60, 3), Test: (39, 60, 3)\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 211ms/step - accuracy: 0.4766 - loss: 0.6918 - val_accuracy: 0.5385 - val_loss: 0.6915\n",
            "Epoch 2/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 143ms/step - accuracy: 0.5435 - loss: 0.6911 - val_accuracy: 0.5385 - val_loss: 0.6917\n",
            "Epoch 3/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 143ms/step - accuracy: 0.5405 - loss: 0.6890 - val_accuracy: 0.5385 - val_loss: 0.6917\n",
            "Epoch 4/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - accuracy: 0.5301 - loss: 0.6927 - val_accuracy: 0.5385 - val_loss: 0.6915\n",
            "Epoch 5/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.5192 - loss: 0.6976 - val_accuracy: 0.5385 - val_loss: 0.6915\n",
            "Epoch 6/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.5865 - loss: 0.6844 - val_accuracy: 0.5385 - val_loss: 0.6916\n",
            "Epoch 7/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - accuracy: 0.5192 - loss: 0.6927 - val_accuracy: 0.5385 - val_loss: 0.6916\n",
            "Epoch 8/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.5487 - loss: 0.6900 - val_accuracy: 0.5385 - val_loss: 0.6914\n",
            "Epoch 9/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.4827 - loss: 0.6976 - val_accuracy: 0.5385 - val_loss: 0.6913\n",
            "Epoch 10/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - accuracy: 0.5075 - loss: 0.6929 - val_accuracy: 0.5385 - val_loss: 0.6915\n",
            "Epoch 11/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - accuracy: 0.5145 - loss: 0.6930 - val_accuracy: 0.5385 - val_loss: 0.6915\n",
            "Epoch 12/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.5540 - loss: 0.6895 - val_accuracy: 0.5385 - val_loss: 0.6920\n",
            "Epoch 13/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - accuracy: 0.5501 - loss: 0.6900 - val_accuracy: 0.5385 - val_loss: 0.6917\n",
            "Epoch 14/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - accuracy: 0.5709 - loss: 0.6784 - val_accuracy: 0.5385 - val_loss: 0.6923\n",
            "Epoch 15/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - accuracy: 0.5171 - loss: 0.6974 - val_accuracy: 0.5385 - val_loss: 0.6919\n",
            "Epoch 16/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.5665 - loss: 0.6829 - val_accuracy: 0.5385 - val_loss: 0.6922\n",
            "Epoch 17/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - accuracy: 0.5366 - loss: 0.6900 - val_accuracy: 0.5385 - val_loss: 0.6921\n",
            "Epoch 18/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.5058 - loss: 0.6909 - val_accuracy: 0.5385 - val_loss: 0.6921\n",
            "Epoch 19/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.5157 - loss: 0.6886 - val_accuracy: 0.5385 - val_loss: 0.6921\n",
            "Epoch 20/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.5145 - loss: 0.6957 - val_accuracy: 0.5385 - val_loss: 0.6926\n",
            "Epoch 21/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 136ms/step - accuracy: 0.5379 - loss: 0.6939 - val_accuracy: 0.5385 - val_loss: 0.6932\n",
            "Epoch 22/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - accuracy: 0.5778 - loss: 0.6786 - val_accuracy: 0.5385 - val_loss: 0.6935\n",
            "Epoch 23/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.5748 - loss: 0.6831 - val_accuracy: 0.5385 - val_loss: 0.6924\n",
            "Epoch 24/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - accuracy: 0.5071 - loss: 0.6963 - val_accuracy: 0.5385 - val_loss: 0.6934\n",
            "Epoch 25/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.5332 - loss: 0.6952 - val_accuracy: 0.5385 - val_loss: 0.6935\n",
            "Epoch 26/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.6323 - loss: 0.6843 - val_accuracy: 0.5385 - val_loss: 0.6918\n",
            "Epoch 27/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.4954 - loss: 0.6924 - val_accuracy: 0.5385 - val_loss: 0.6918\n",
            "Epoch 28/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - accuracy: 0.5461 - loss: 0.6924 - val_accuracy: 0.5385 - val_loss: 0.6921\n",
            "Epoch 29/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.5071 - loss: 0.6988 - val_accuracy: 0.5385 - val_loss: 0.6922\n",
            "Epoch 30/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.5071 - loss: 0.6932 - val_accuracy: 0.5385 - val_loss: 0.6922\n",
            "Epoch 31/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.4984 - loss: 0.7003 - val_accuracy: 0.5385 - val_loss: 0.6921\n",
            "Epoch 32/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.5501 - loss: 0.6926 - val_accuracy: 0.5385 - val_loss: 0.6925\n",
            "Epoch 33/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - accuracy: 0.5227 - loss: 0.6942 - val_accuracy: 0.5385 - val_loss: 0.6929\n",
            "Epoch 34/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.5080 - loss: 0.6949 - val_accuracy: 0.5385 - val_loss: 0.6931\n",
            "Epoch 35/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.5644 - loss: 0.6886 - val_accuracy: 0.5385 - val_loss: 0.6937\n",
            "Epoch 36/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.5358 - loss: 0.6921 - val_accuracy: 0.5385 - val_loss: 0.6947\n",
            "Epoch 37/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - accuracy: 0.5317 - loss: 0.6887 - val_accuracy: 0.5385 - val_loss: 0.6943\n",
            "Epoch 38/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - accuracy: 0.5057 - loss: 0.6929 - val_accuracy: 0.5385 - val_loss: 0.6948\n",
            "Epoch 39/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.6356 - loss: 0.6741 - val_accuracy: 0.5385 - val_loss: 0.6956\n",
            "Epoch 40/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - accuracy: 0.5562 - loss: 0.6944 - val_accuracy: 0.4872 - val_loss: 0.6968\n",
            "Epoch 41/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - accuracy: 0.5606 - loss: 0.6888 - val_accuracy: 0.4359 - val_loss: 0.6980\n",
            "Epoch 42/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - accuracy: 0.5614 - loss: 0.6867 - val_accuracy: 0.5385 - val_loss: 0.6977\n",
            "Epoch 43/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 141ms/step - accuracy: 0.5841 - loss: 0.6839 - val_accuracy: 0.5128 - val_loss: 0.6981\n",
            "Epoch 44/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 131ms/step - accuracy: 0.5227 - loss: 0.6893 - val_accuracy: 0.5385 - val_loss: 0.6980\n",
            "Epoch 45/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.5297 - loss: 0.6959 - val_accuracy: 0.5385 - val_loss: 0.6982\n",
            "Epoch 46/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.6022 - loss: 0.6783 - val_accuracy: 0.5128 - val_loss: 0.7014\n",
            "Epoch 47/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.5744 - loss: 0.6806 - val_accuracy: 0.5128 - val_loss: 0.7012\n",
            "Epoch 48/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.5631 - loss: 0.6851 - val_accuracy: 0.4872 - val_loss: 0.7014\n",
            "Epoch 49/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.6031 - loss: 0.6768 - val_accuracy: 0.5385 - val_loss: 0.6959\n",
            "Epoch 50/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.5510 - loss: 0.6881 - val_accuracy: 0.5385 - val_loss: 0.6948\n",
            "Epoch 51/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - accuracy: 0.5610 - loss: 0.6808 - val_accuracy: 0.5385 - val_loss: 0.6967\n",
            "Epoch 52/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - accuracy: 0.6036 - loss: 0.6823 - val_accuracy: 0.4359 - val_loss: 0.7010\n",
            "Epoch 53/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - accuracy: 0.5189 - loss: 0.7020 - val_accuracy: 0.4359 - val_loss: 0.7004\n",
            "Epoch 54/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.5357 - loss: 0.6896 - val_accuracy: 0.4359 - val_loss: 0.7016\n",
            "Epoch 55/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.6162 - loss: 0.6778 - val_accuracy: 0.4103 - val_loss: 0.7029\n",
            "Epoch 56/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.6026 - loss: 0.6774 - val_accuracy: 0.5385 - val_loss: 0.6978\n",
            "Epoch 57/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.5862 - loss: 0.6830 - val_accuracy: 0.5128 - val_loss: 0.7009\n",
            "Epoch 58/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - accuracy: 0.6101 - loss: 0.6839 - val_accuracy: 0.4359 - val_loss: 0.7190\n",
            "Epoch 59/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.5683 - loss: 0.6829 - val_accuracy: 0.5385 - val_loss: 0.6925\n",
            "Epoch 60/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.5058 - loss: 0.7004 - val_accuracy: 0.5385 - val_loss: 0.6918\n",
            "Epoch 61/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.5448 - loss: 0.6875 - val_accuracy: 0.5385 - val_loss: 0.6922\n",
            "Epoch 62/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - accuracy: 0.5605 - loss: 0.6881 - val_accuracy: 0.5385 - val_loss: 0.6928\n",
            "Epoch 63/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.6009 - loss: 0.6811 - val_accuracy: 0.5385 - val_loss: 0.6937\n",
            "Epoch 64/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - accuracy: 0.5962 - loss: 0.6822 - val_accuracy: 0.5385 - val_loss: 0.6960\n",
            "Epoch 65/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - accuracy: 0.5967 - loss: 0.6857 - val_accuracy: 0.4872 - val_loss: 0.7008\n",
            "Epoch 66/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - accuracy: 0.5801 - loss: 0.6825 - val_accuracy: 0.4359 - val_loss: 0.7066\n",
            "Epoch 67/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - accuracy: 0.5419 - loss: 0.6878 - val_accuracy: 0.4359 - val_loss: 0.7034\n",
            "Epoch 68/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.5749 - loss: 0.6794 - val_accuracy: 0.5385 - val_loss: 0.7003\n",
            "Epoch 69/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.5857 - loss: 0.6798 - val_accuracy: 0.5128 - val_loss: 0.7039\n",
            "Epoch 70/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.6036 - loss: 0.6759 - val_accuracy: 0.5128 - val_loss: 0.7051\n",
            "Epoch 71/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - accuracy: 0.5997 - loss: 0.6814 - val_accuracy: 0.4359 - val_loss: 0.7120\n",
            "Epoch 72/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.6104 - loss: 0.6669 - val_accuracy: 0.5385 - val_loss: 0.6945\n",
            "Epoch 73/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.5596 - loss: 0.6805 - val_accuracy: 0.5385 - val_loss: 0.6936\n",
            "Epoch 74/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.5310 - loss: 0.6923 - val_accuracy: 0.5641 - val_loss: 0.6914\n",
            "Epoch 75/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - accuracy: 0.6161 - loss: 0.6757 - val_accuracy: 0.5385 - val_loss: 0.6957\n",
            "Epoch 76/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.5384 - loss: 0.6876 - val_accuracy: 0.4615 - val_loss: 0.7076\n",
            "Epoch 77/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - accuracy: 0.5854 - loss: 0.6828 - val_accuracy: 0.4615 - val_loss: 0.7010\n",
            "Epoch 78/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.5702 - loss: 0.6865 - val_accuracy: 0.5128 - val_loss: 0.6989\n",
            "Epoch 79/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.5953 - loss: 0.6752 - val_accuracy: 0.5128 - val_loss: 0.7001\n",
            "Epoch 80/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - accuracy: 0.6200 - loss: 0.6798 - val_accuracy: 0.5128 - val_loss: 0.7001\n",
            "Epoch 81/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - accuracy: 0.5549 - loss: 0.6836 - val_accuracy: 0.4103 - val_loss: 0.7234\n",
            "Epoch 82/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.5823 - loss: 0.6907 - val_accuracy: 0.5385 - val_loss: 0.6964\n",
            "Epoch 83/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.5536 - loss: 0.6879 - val_accuracy: 0.5385 - val_loss: 0.6966\n",
            "Epoch 84/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - accuracy: 0.6301 - loss: 0.6735 - val_accuracy: 0.4359 - val_loss: 0.7138\n",
            "Epoch 85/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - accuracy: 0.5888 - loss: 0.6795 - val_accuracy: 0.4615 - val_loss: 0.7095\n",
            "Epoch 86/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - accuracy: 0.6336 - loss: 0.6647 - val_accuracy: 0.4615 - val_loss: 0.7131\n",
            "Epoch 87/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - accuracy: 0.5771 - loss: 0.6806 - val_accuracy: 0.5128 - val_loss: 0.7075\n",
            "Epoch 88/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 143ms/step - accuracy: 0.6088 - loss: 0.6638 - val_accuracy: 0.4359 - val_loss: 0.7155\n",
            "Epoch 89/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - accuracy: 0.5867 - loss: 0.6870 - val_accuracy: 0.4103 - val_loss: 0.7185\n",
            "Epoch 90/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.6144 - loss: 0.6764 - val_accuracy: 0.5128 - val_loss: 0.7071\n",
            "Epoch 91/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.5692 - loss: 0.6761 - val_accuracy: 0.4615 - val_loss: 0.7102\n",
            "Epoch 92/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - accuracy: 0.5693 - loss: 0.6752 - val_accuracy: 0.4615 - val_loss: 0.7126\n",
            "Epoch 93/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.5567 - loss: 0.6773 - val_accuracy: 0.4103 - val_loss: 0.7359\n",
            "Epoch 94/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - accuracy: 0.6244 - loss: 0.6702 - val_accuracy: 0.5385 - val_loss: 0.7004\n",
            "Epoch 95/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - accuracy: 0.6123 - loss: 0.6727 - val_accuracy: 0.4615 - val_loss: 0.7174\n",
            "Epoch 96/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.5857 - loss: 0.6654 - val_accuracy: 0.4615 - val_loss: 0.7275\n",
            "Epoch 97/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.5905 - loss: 0.6600 - val_accuracy: 0.4872 - val_loss: 0.7017\n",
            "Epoch 98/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 212ms/step - accuracy: 0.5940 - loss: 0.6817 - val_accuracy: 0.4872 - val_loss: 0.7075\n",
            "Epoch 99/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 197ms/step - accuracy: 0.5901 - loss: 0.6753 - val_accuracy: 0.5128 - val_loss: 0.7298\n",
            "Epoch 100/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.5761 - loss: 0.6726 - val_accuracy: 0.5641 - val_loss: 0.6987\n",
            "AAPL - Test accuracy: 0.5641\n",
            "Saved model for AAPL to /content/model_AAPL.h5\n",
            "Training LSTM for MSFT\n",
            "MSFT - Train: (152, 60, 3), Test: (39, 60, 3)\n",
            "Epoch 1/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 211ms/step - accuracy: 0.4752 - loss: 0.6920 - val_accuracy: 0.3590 - val_loss: 0.7076\n",
            "Epoch 2/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.5665 - loss: 0.6904 - val_accuracy: 0.3590 - val_loss: 0.7143\n",
            "Epoch 3/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.5587 - loss: 0.6858 - val_accuracy: 0.3590 - val_loss: 0.7127\n",
            "Epoch 4/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.5153 - loss: 0.6942 - val_accuracy: 0.3590 - val_loss: 0.7044\n",
            "Epoch 5/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - accuracy: 0.5466 - loss: 0.6897 - val_accuracy: 0.3590 - val_loss: 0.7067\n",
            "Epoch 6/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - accuracy: 0.5196 - loss: 0.6930 - val_accuracy: 0.3590 - val_loss: 0.7072\n",
            "Epoch 7/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.5626 - loss: 0.6864 - val_accuracy: 0.3590 - val_loss: 0.7196\n",
            "Epoch 8/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.5097 - loss: 0.6954 - val_accuracy: 0.3590 - val_loss: 0.7137\n",
            "Epoch 9/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - accuracy: 0.5214 - loss: 0.6949 - val_accuracy: 0.3590 - val_loss: 0.7119\n",
            "Epoch 10/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - accuracy: 0.5092 - loss: 0.6940 - val_accuracy: 0.3590 - val_loss: 0.7109\n",
            "Epoch 11/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.5426 - loss: 0.6904 - val_accuracy: 0.3590 - val_loss: 0.7154\n",
            "Epoch 12/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - accuracy: 0.5340 - loss: 0.6892 - val_accuracy: 0.3590 - val_loss: 0.7189\n",
            "Epoch 13/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.5418 - loss: 0.6903 - val_accuracy: 0.3590 - val_loss: 0.7193\n",
            "Epoch 14/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.5144 - loss: 0.6957 - val_accuracy: 0.3590 - val_loss: 0.7126\n",
            "Epoch 15/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - accuracy: 0.5405 - loss: 0.6919 - val_accuracy: 0.3590 - val_loss: 0.7145\n",
            "Epoch 16/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.5392 - loss: 0.6897 - val_accuracy: 0.3590 - val_loss: 0.7166\n",
            "Epoch 17/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - accuracy: 0.5413 - loss: 0.6869 - val_accuracy: 0.3590 - val_loss: 0.7198\n",
            "Epoch 18/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.5518 - loss: 0.6806 - val_accuracy: 0.3590 - val_loss: 0.7094\n",
            "Epoch 19/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - accuracy: 0.5596 - loss: 0.6801 - val_accuracy: 0.3590 - val_loss: 0.7056\n",
            "Epoch 20/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - accuracy: 0.5092 - loss: 0.6797 - val_accuracy: 0.3590 - val_loss: 0.6960\n",
            "Epoch 21/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - accuracy: 0.5270 - loss: 0.6812 - val_accuracy: 0.3590 - val_loss: 0.7090\n",
            "Epoch 22/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 142ms/step - accuracy: 0.5605 - loss: 0.6705 - val_accuracy: 0.3590 - val_loss: 0.7075\n",
            "Epoch 23/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.5057 - loss: 0.6866 - val_accuracy: 0.3846 - val_loss: 0.6975\n",
            "Epoch 24/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.5152 - loss: 0.6823 - val_accuracy: 0.3846 - val_loss: 0.7049\n",
            "Epoch 25/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - accuracy: 0.5244 - loss: 0.6735 - val_accuracy: 0.4359 - val_loss: 0.7075\n",
            "Epoch 26/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - accuracy: 0.5209 - loss: 0.6763 - val_accuracy: 0.4359 - val_loss: 0.6886\n",
            "Epoch 27/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - accuracy: 0.5895 - loss: 0.6661 - val_accuracy: 0.4359 - val_loss: 0.6926\n",
            "Epoch 28/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.5696 - loss: 0.6773 - val_accuracy: 0.4615 - val_loss: 0.7000\n",
            "Epoch 29/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - accuracy: 0.5719 - loss: 0.6795 - val_accuracy: 0.4103 - val_loss: 0.6999\n",
            "Epoch 30/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.5467 - loss: 0.6679 - val_accuracy: 0.4359 - val_loss: 0.7055\n",
            "Epoch 31/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - accuracy: 0.5983 - loss: 0.6528 - val_accuracy: 0.4359 - val_loss: 0.7014\n",
            "Epoch 32/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 145ms/step - accuracy: 0.5149 - loss: 0.6629 - val_accuracy: 0.4359 - val_loss: 0.6893\n",
            "Epoch 33/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - accuracy: 0.5479 - loss: 0.6621 - val_accuracy: 0.4103 - val_loss: 0.6918\n",
            "Epoch 34/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.5944 - loss: 0.6682 - val_accuracy: 0.5128 - val_loss: 0.7015\n",
            "Epoch 35/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.5376 - loss: 0.6701 - val_accuracy: 0.5641 - val_loss: 0.7098\n",
            "Epoch 36/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.5775 - loss: 0.6922 - val_accuracy: 0.4359 - val_loss: 0.6928\n",
            "Epoch 37/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - accuracy: 0.4832 - loss: 0.6856 - val_accuracy: 0.4103 - val_loss: 0.6926\n",
            "Epoch 38/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.4857 - loss: 0.6763 - val_accuracy: 0.4359 - val_loss: 0.6998\n",
            "Epoch 39/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.5853 - loss: 0.6597 - val_accuracy: 0.4359 - val_loss: 0.7081\n",
            "Epoch 40/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - accuracy: 0.5179 - loss: 0.6698 - val_accuracy: 0.4359 - val_loss: 0.7006\n",
            "Epoch 41/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 146ms/step - accuracy: 0.5645 - loss: 0.6696 - val_accuracy: 0.4615 - val_loss: 0.6937\n",
            "Epoch 42/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 149ms/step - accuracy: 0.5500 - loss: 0.6707 - val_accuracy: 0.4615 - val_loss: 0.6968\n",
            "Epoch 43/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 146ms/step - accuracy: 0.5132 - loss: 0.6835 - val_accuracy: 0.4615 - val_loss: 0.6996\n",
            "Epoch 44/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - accuracy: 0.5405 - loss: 0.6564 - val_accuracy: 0.4615 - val_loss: 0.7112\n",
            "Epoch 45/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - accuracy: 0.4714 - loss: 0.6746 - val_accuracy: 0.4359 - val_loss: 0.6968\n",
            "Epoch 46/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - accuracy: 0.5504 - loss: 0.6678 - val_accuracy: 0.4615 - val_loss: 0.6959\n",
            "Epoch 47/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - accuracy: 0.5218 - loss: 0.6666 - val_accuracy: 0.4103 - val_loss: 0.6972\n",
            "Epoch 48/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - accuracy: 0.5779 - loss: 0.6604 - val_accuracy: 0.5385 - val_loss: 0.7046\n",
            "Epoch 49/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.5337 - loss: 0.6803 - val_accuracy: 0.4872 - val_loss: 0.6907\n",
            "Epoch 50/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - accuracy: 0.5356 - loss: 0.6682 - val_accuracy: 0.4359 - val_loss: 0.6934\n",
            "Epoch 51/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.5319 - loss: 0.6731 - val_accuracy: 0.5128 - val_loss: 0.6936\n",
            "Epoch 52/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.5679 - loss: 0.6676 - val_accuracy: 0.5385 - val_loss: 0.6892\n",
            "Epoch 53/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - accuracy: 0.5475 - loss: 0.6609 - val_accuracy: 0.5385 - val_loss: 0.6955\n",
            "Epoch 54/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.6053 - loss: 0.6702 - val_accuracy: 0.4872 - val_loss: 0.6932\n",
            "Epoch 55/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.5553 - loss: 0.6656 - val_accuracy: 0.4359 - val_loss: 0.6882\n",
            "Epoch 56/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.5683 - loss: 0.6658 - val_accuracy: 0.4359 - val_loss: 0.6931\n",
            "Epoch 57/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - accuracy: 0.5666 - loss: 0.6776 - val_accuracy: 0.4872 - val_loss: 0.6873\n",
            "Epoch 58/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.5871 - loss: 0.6584 - val_accuracy: 0.6667 - val_loss: 0.6889\n",
            "Epoch 59/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - accuracy: 0.5593 - loss: 0.6563 - val_accuracy: 0.5641 - val_loss: 0.6892\n",
            "Epoch 60/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.5492 - loss: 0.6690 - val_accuracy: 0.4872 - val_loss: 0.6821\n",
            "Epoch 61/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.5195 - loss: 0.6728 - val_accuracy: 0.4872 - val_loss: 0.6807\n",
            "Epoch 62/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 141ms/step - accuracy: 0.5692 - loss: 0.6632 - val_accuracy: 0.6410 - val_loss: 0.6802\n",
            "Epoch 63/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 146ms/step - accuracy: 0.5318 - loss: 0.6780 - val_accuracy: 0.5385 - val_loss: 0.6874\n",
            "Epoch 64/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 144ms/step - accuracy: 0.5506 - loss: 0.6921 - val_accuracy: 0.4872 - val_loss: 0.6805\n",
            "Epoch 65/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.5466 - loss: 0.6795 - val_accuracy: 0.4615 - val_loss: 0.6858\n",
            "Epoch 66/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.5692 - loss: 0.6615 - val_accuracy: 0.7179 - val_loss: 0.6795\n",
            "Epoch 67/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - accuracy: 0.4914 - loss: 0.6808 - val_accuracy: 0.7692 - val_loss: 0.6826\n",
            "Epoch 68/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - accuracy: 0.5462 - loss: 0.6768 - val_accuracy: 0.7179 - val_loss: 0.6732\n",
            "Epoch 69/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.5884 - loss: 0.6681 - val_accuracy: 0.4872 - val_loss: 0.6804\n",
            "Epoch 70/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - accuracy: 0.5679 - loss: 0.6641 - val_accuracy: 0.5385 - val_loss: 0.6820\n",
            "Epoch 71/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.5636 - loss: 0.6755 - val_accuracy: 0.5641 - val_loss: 0.6790\n",
            "Epoch 72/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.5993 - loss: 0.6602 - val_accuracy: 0.5641 - val_loss: 0.6854\n",
            "Epoch 73/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.5883 - loss: 0.6642 - val_accuracy: 0.5128 - val_loss: 0.6844\n",
            "Epoch 74/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.5644 - loss: 0.6680 - val_accuracy: 0.7179 - val_loss: 0.6750\n",
            "Epoch 75/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.5783 - loss: 0.6743 - val_accuracy: 0.7179 - val_loss: 0.6770\n",
            "Epoch 76/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.5417 - loss: 0.6792 - val_accuracy: 0.6410 - val_loss: 0.6722\n",
            "Epoch 77/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - accuracy: 0.5979 - loss: 0.6624 - val_accuracy: 0.5385 - val_loss: 0.6780\n",
            "Epoch 78/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.6280 - loss: 0.6565 - val_accuracy: 0.5897 - val_loss: 0.6791\n",
            "Epoch 79/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.5663 - loss: 0.6730 - val_accuracy: 0.6154 - val_loss: 0.6773\n",
            "Epoch 80/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.5653 - loss: 0.6758 - val_accuracy: 0.6667 - val_loss: 0.6704\n",
            "Epoch 81/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.6079 - loss: 0.6460 - val_accuracy: 0.5128 - val_loss: 0.6844\n",
            "Epoch 82/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.5510 - loss: 0.6632 - val_accuracy: 0.4872 - val_loss: 0.6873\n",
            "Epoch 83/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.6071 - loss: 0.6687 - val_accuracy: 0.5897 - val_loss: 0.6763\n",
            "Epoch 84/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 134ms/step - accuracy: 0.5450 - loss: 0.6633 - val_accuracy: 0.6667 - val_loss: 0.6759\n",
            "Epoch 85/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 131ms/step - accuracy: 0.6088 - loss: 0.6616 - val_accuracy: 0.6410 - val_loss: 0.6690\n",
            "Epoch 86/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - accuracy: 0.5132 - loss: 0.6790 - val_accuracy: 0.6154 - val_loss: 0.6697\n",
            "Epoch 87/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - accuracy: 0.5819 - loss: 0.6654 - val_accuracy: 0.6410 - val_loss: 0.6650\n",
            "Epoch 88/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 174ms/step - accuracy: 0.5789 - loss: 0.6626 - val_accuracy: 0.6923 - val_loss: 0.6718\n",
            "Epoch 89/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.5710 - loss: 0.6689 - val_accuracy: 0.6923 - val_loss: 0.6707\n",
            "Epoch 90/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.6318 - loss: 0.6751 - val_accuracy: 0.6410 - val_loss: 0.6699\n",
            "Epoch 91/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - accuracy: 0.5749 - loss: 0.6719 - val_accuracy: 0.6154 - val_loss: 0.6727\n",
            "Epoch 92/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.6032 - loss: 0.6573 - val_accuracy: 0.6923 - val_loss: 0.6749\n",
            "Epoch 93/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.5775 - loss: 0.6534 - val_accuracy: 0.7179 - val_loss: 0.6808\n",
            "Epoch 94/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - accuracy: 0.6210 - loss: 0.6468 - val_accuracy: 0.6923 - val_loss: 0.6773\n",
            "Epoch 95/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - accuracy: 0.6179 - loss: 0.6412 - val_accuracy: 0.7179 - val_loss: 0.6697\n",
            "Epoch 96/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - accuracy: 0.5932 - loss: 0.6583 - val_accuracy: 0.6923 - val_loss: 0.6719\n",
            "Epoch 97/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - accuracy: 0.5879 - loss: 0.6591 - val_accuracy: 0.6923 - val_loss: 0.6630\n",
            "Epoch 98/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - accuracy: 0.6110 - loss: 0.6560 - val_accuracy: 0.6923 - val_loss: 0.6600\n",
            "Epoch 99/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.5936 - loss: 0.6557 - val_accuracy: 0.5641 - val_loss: 0.6688\n",
            "Epoch 100/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.6072 - loss: 0.6535 - val_accuracy: 0.6923 - val_loss: 0.6617\n",
            "MSFT - Test accuracy: 0.6923\n",
            "Saved model for MSFT to /content/model_MSFT.h5\n",
            "Training LSTM for GOOGL\n",
            "GOOGL - Train: (152, 60, 3), Test: (39, 60, 3)\n",
            "Epoch 1/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 219ms/step - accuracy: 0.5139 - loss: 0.6955 - val_accuracy: 0.4872 - val_loss: 0.6956\n",
            "Epoch 2/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.5127 - loss: 0.6926 - val_accuracy: 0.4872 - val_loss: 0.6938\n",
            "Epoch 3/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - accuracy: 0.5384 - loss: 0.6914 - val_accuracy: 0.4872 - val_loss: 0.6943\n",
            "Epoch 4/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - accuracy: 0.5327 - loss: 0.6929 - val_accuracy: 0.4615 - val_loss: 0.6945\n",
            "Epoch 5/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.4887 - loss: 0.6928 - val_accuracy: 0.4615 - val_loss: 0.6938\n",
            "Epoch 6/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.5314 - loss: 0.6916 - val_accuracy: 0.4872 - val_loss: 0.6934\n",
            "Epoch 7/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.5195 - loss: 0.6902 - val_accuracy: 0.4615 - val_loss: 0.6937\n",
            "Epoch 8/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - accuracy: 0.5769 - loss: 0.6834 - val_accuracy: 0.5385 - val_loss: 0.6915\n",
            "Epoch 9/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.5488 - loss: 0.6857 - val_accuracy: 0.5128 - val_loss: 0.6922\n",
            "Epoch 10/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.5322 - loss: 0.6846 - val_accuracy: 0.5128 - val_loss: 0.6931\n",
            "Epoch 11/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.5506 - loss: 0.6855 - val_accuracy: 0.5641 - val_loss: 0.6888\n",
            "Epoch 12/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.5680 - loss: 0.6841 - val_accuracy: 0.5128 - val_loss: 0.6991\n",
            "Epoch 13/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - accuracy: 0.5923 - loss: 0.6795 - val_accuracy: 0.5385 - val_loss: 0.6984\n",
            "Epoch 14/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.5454 - loss: 0.6977 - val_accuracy: 0.5128 - val_loss: 0.7092\n",
            "Epoch 15/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - accuracy: 0.5637 - loss: 0.6953 - val_accuracy: 0.5128 - val_loss: 0.7004\n",
            "Epoch 16/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - accuracy: 0.6114 - loss: 0.6786 - val_accuracy: 0.5128 - val_loss: 0.6983\n",
            "Epoch 17/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 147ms/step - accuracy: 0.5884 - loss: 0.6703 - val_accuracy: 0.5128 - val_loss: 0.7066\n",
            "Epoch 18/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 155ms/step - accuracy: 0.5923 - loss: 0.6638 - val_accuracy: 0.4872 - val_loss: 0.6901\n",
            "Epoch 19/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - accuracy: 0.5823 - loss: 0.6804 - val_accuracy: 0.5385 - val_loss: 0.6857\n",
            "Epoch 20/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.5962 - loss: 0.6738 - val_accuracy: 0.5128 - val_loss: 0.6907\n",
            "Epoch 21/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - accuracy: 0.6205 - loss: 0.6675 - val_accuracy: 0.4872 - val_loss: 0.7085\n",
            "Epoch 22/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.6153 - loss: 0.6747 - val_accuracy: 0.5641 - val_loss: 0.6883\n",
            "Epoch 23/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - accuracy: 0.6175 - loss: 0.6736 - val_accuracy: 0.5128 - val_loss: 0.7068\n",
            "Epoch 24/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.5471 - loss: 0.6887 - val_accuracy: 0.4615 - val_loss: 0.6992\n",
            "Epoch 25/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.5320 - loss: 0.6961 - val_accuracy: 0.4615 - val_loss: 0.6967\n",
            "Epoch 26/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.6391 - loss: 0.6569 - val_accuracy: 0.5128 - val_loss: 0.7097\n",
            "Epoch 27/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.6079 - loss: 0.6662 - val_accuracy: 0.4359 - val_loss: 0.7021\n",
            "Epoch 28/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.5802 - loss: 0.6760 - val_accuracy: 0.4615 - val_loss: 0.6960\n",
            "Epoch 29/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.5606 - loss: 0.6808 - val_accuracy: 0.4615 - val_loss: 0.6959\n",
            "Epoch 30/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.6383 - loss: 0.6661 - val_accuracy: 0.4615 - val_loss: 0.7002\n",
            "Epoch 31/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.5867 - loss: 0.6773 - val_accuracy: 0.4615 - val_loss: 0.7035\n",
            "Epoch 32/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.6426 - loss: 0.6638 - val_accuracy: 0.4615 - val_loss: 0.7071\n",
            "Epoch 33/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - accuracy: 0.5432 - loss: 0.6852 - val_accuracy: 0.4872 - val_loss: 0.6961\n",
            "Epoch 34/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.5797 - loss: 0.6712 - val_accuracy: 0.4615 - val_loss: 0.7020\n",
            "Epoch 35/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.5824 - loss: 0.6742 - val_accuracy: 0.4615 - val_loss: 0.7003\n",
            "Epoch 36/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.5989 - loss: 0.6676 - val_accuracy: 0.4615 - val_loss: 0.6954\n",
            "Epoch 37/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.5771 - loss: 0.6799 - val_accuracy: 0.5385 - val_loss: 0.7013\n",
            "Epoch 38/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - accuracy: 0.6175 - loss: 0.6562 - val_accuracy: 0.4615 - val_loss: 0.7021\n",
            "Epoch 39/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - accuracy: 0.6062 - loss: 0.6677 - val_accuracy: 0.4872 - val_loss: 0.7009\n",
            "Epoch 40/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - accuracy: 0.5562 - loss: 0.6839 - val_accuracy: 0.5385 - val_loss: 0.6940\n",
            "Epoch 41/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 142ms/step - accuracy: 0.5502 - loss: 0.6952 - val_accuracy: 0.4872 - val_loss: 0.7038\n",
            "Epoch 42/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 154ms/step - accuracy: 0.5471 - loss: 0.6815 - val_accuracy: 0.4872 - val_loss: 0.7086\n",
            "Epoch 43/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.5740 - loss: 0.6763 - val_accuracy: 0.4615 - val_loss: 0.7000\n",
            "Epoch 44/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.6088 - loss: 0.6650 - val_accuracy: 0.5128 - val_loss: 0.6966\n",
            "Epoch 45/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.5563 - loss: 0.6847 - val_accuracy: 0.4872 - val_loss: 0.6984\n",
            "Epoch 46/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.5740 - loss: 0.6703 - val_accuracy: 0.4872 - val_loss: 0.7035\n",
            "Epoch 47/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - accuracy: 0.5549 - loss: 0.6880 - val_accuracy: 0.4872 - val_loss: 0.6959\n",
            "Epoch 48/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.5832 - loss: 0.6660 - val_accuracy: 0.5128 - val_loss: 0.6994\n",
            "Epoch 49/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - accuracy: 0.5472 - loss: 0.6865 - val_accuracy: 0.5128 - val_loss: 0.6980\n",
            "Epoch 50/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - accuracy: 0.5697 - loss: 0.6722 - val_accuracy: 0.4872 - val_loss: 0.6987\n",
            "Epoch 51/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - accuracy: 0.5945 - loss: 0.6769 - val_accuracy: 0.4872 - val_loss: 0.6973\n",
            "Epoch 52/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.5828 - loss: 0.6727 - val_accuracy: 0.5128 - val_loss: 0.7012\n",
            "Epoch 53/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.5971 - loss: 0.6796 - val_accuracy: 0.5128 - val_loss: 0.7011\n",
            "Epoch 54/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.5884 - loss: 0.6654 - val_accuracy: 0.5128 - val_loss: 0.7029\n",
            "Epoch 55/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - accuracy: 0.5611 - loss: 0.6901 - val_accuracy: 0.4615 - val_loss: 0.6998\n",
            "Epoch 56/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - accuracy: 0.6258 - loss: 0.6674 - val_accuracy: 0.4615 - val_loss: 0.7013\n",
            "Epoch 57/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.6318 - loss: 0.6558 - val_accuracy: 0.4615 - val_loss: 0.6994\n",
            "Epoch 58/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.5850 - loss: 0.6820 - val_accuracy: 0.4615 - val_loss: 0.6959\n",
            "Epoch 59/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - accuracy: 0.5675 - loss: 0.6690 - val_accuracy: 0.4872 - val_loss: 0.6913\n",
            "Epoch 60/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.5932 - loss: 0.6765 - val_accuracy: 0.4872 - val_loss: 0.6910\n",
            "Epoch 61/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 146ms/step - accuracy: 0.6045 - loss: 0.6699 - val_accuracy: 0.5128 - val_loss: 0.6955\n",
            "Epoch 62/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 146ms/step - accuracy: 0.5381 - loss: 0.6880 - val_accuracy: 0.5128 - val_loss: 0.6969\n",
            "Epoch 63/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - accuracy: 0.5545 - loss: 0.6832 - val_accuracy: 0.4615 - val_loss: 0.7045\n",
            "Epoch 64/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - accuracy: 0.5789 - loss: 0.6740 - val_accuracy: 0.5128 - val_loss: 0.7020\n",
            "Epoch 65/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - accuracy: 0.6115 - loss: 0.6677 - val_accuracy: 0.5128 - val_loss: 0.7021\n",
            "Epoch 66/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.6297 - loss: 0.6626 - val_accuracy: 0.4615 - val_loss: 0.7045\n",
            "Epoch 67/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - accuracy: 0.5532 - loss: 0.6855 - val_accuracy: 0.4615 - val_loss: 0.7007\n",
            "Epoch 68/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.6241 - loss: 0.6653 - val_accuracy: 0.5128 - val_loss: 0.6997\n",
            "Epoch 69/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.5694 - loss: 0.6884 - val_accuracy: 0.4615 - val_loss: 0.6917\n",
            "Epoch 70/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - accuracy: 0.5615 - loss: 0.6796 - val_accuracy: 0.5128 - val_loss: 0.6928\n",
            "Epoch 71/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 0.6384 - loss: 0.6681 - val_accuracy: 0.4872 - val_loss: 0.6944\n",
            "Epoch 72/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - accuracy: 0.6201 - loss: 0.6649 - val_accuracy: 0.5385 - val_loss: 0.6991\n",
            "Epoch 73/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.5688 - loss: 0.6760 - val_accuracy: 0.5128 - val_loss: 0.6971\n",
            "Epoch 74/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - accuracy: 0.5775 - loss: 0.6666 - val_accuracy: 0.5128 - val_loss: 0.6988\n",
            "Epoch 75/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 0.5715 - loss: 0.6862 - val_accuracy: 0.5128 - val_loss: 0.6909\n",
            "Epoch 76/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.6362 - loss: 0.6544 - val_accuracy: 0.4872 - val_loss: 0.6960\n",
            "Epoch 77/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.5585 - loss: 0.6817 - val_accuracy: 0.5128 - val_loss: 0.6954\n",
            "Epoch 78/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.6041 - loss: 0.6685 - val_accuracy: 0.5385 - val_loss: 0.7033\n",
            "Epoch 79/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.6618 - loss: 0.6567 - val_accuracy: 0.5128 - val_loss: 0.7072\n",
            "Epoch 80/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - accuracy: 0.6393 - loss: 0.6521 - val_accuracy: 0.5128 - val_loss: 0.6969\n",
            "Epoch 81/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 148ms/step - accuracy: 0.5603 - loss: 0.6914 - val_accuracy: 0.5128 - val_loss: 0.6882\n",
            "Epoch 82/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 144ms/step - accuracy: 0.5715 - loss: 0.6731 - val_accuracy: 0.5128 - val_loss: 0.6898\n",
            "Epoch 83/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 147ms/step - accuracy: 0.6157 - loss: 0.6622 - val_accuracy: 0.4872 - val_loss: 0.6971\n",
            "Epoch 84/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - accuracy: 0.5840 - loss: 0.6671 - val_accuracy: 0.5385 - val_loss: 0.6982\n",
            "Epoch 85/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.5476 - loss: 0.6792 - val_accuracy: 0.5641 - val_loss: 0.6957\n",
            "Epoch 86/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - accuracy: 0.5793 - loss: 0.6714 - val_accuracy: 0.5128 - val_loss: 0.6920\n",
            "Epoch 87/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.5837 - loss: 0.6853 - val_accuracy: 0.5128 - val_loss: 0.6922\n",
            "Epoch 88/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.6114 - loss: 0.6586 - val_accuracy: 0.5128 - val_loss: 0.6987\n",
            "Epoch 89/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - accuracy: 0.6184 - loss: 0.6611 - val_accuracy: 0.5641 - val_loss: 0.7057\n",
            "Epoch 90/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - accuracy: 0.6696 - loss: 0.6297 - val_accuracy: 0.5641 - val_loss: 0.7092\n",
            "Epoch 91/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - accuracy: 0.5749 - loss: 0.6709 - val_accuracy: 0.5128 - val_loss: 0.6980\n",
            "Epoch 92/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - accuracy: 0.5725 - loss: 0.6728 - val_accuracy: 0.5641 - val_loss: 0.6960\n",
            "Epoch 93/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.5907 - loss: 0.6695 - val_accuracy: 0.5641 - val_loss: 0.7065\n",
            "Epoch 94/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.5993 - loss: 0.6498 - val_accuracy: 0.5641 - val_loss: 0.7119\n",
            "Epoch 95/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.5801 - loss: 0.6615 - val_accuracy: 0.5641 - val_loss: 0.7117\n",
            "Epoch 96/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - accuracy: 0.6350 - loss: 0.6578 - val_accuracy: 0.5897 - val_loss: 0.7309\n",
            "Epoch 97/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 0.6167 - loss: 0.6337 - val_accuracy: 0.5897 - val_loss: 0.7472\n",
            "Epoch 98/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - accuracy: 0.6332 - loss: 0.6453 - val_accuracy: 0.5385 - val_loss: 0.7228\n",
            "Epoch 99/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - accuracy: 0.6854 - loss: 0.6292 - val_accuracy: 0.5385 - val_loss: 0.7368\n",
            "Epoch 100/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.6394 - loss: 0.6350 - val_accuracy: 0.5641 - val_loss: 0.7483\n",
            "GOOGL - Test accuracy: 0.5641\n",
            "Saved model for GOOGL to /content/model_GOOGL.h5\n",
            "Training LSTM for TSLA\n",
            "TSLA - Train: (152, 60, 3), Test: (39, 60, 3)\n",
            "Epoch 1/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 218ms/step - accuracy: 0.4404 - loss: 0.6978 - val_accuracy: 0.5641 - val_loss: 0.6879\n",
            "Epoch 2/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - accuracy: 0.5366 - loss: 0.6935 - val_accuracy: 0.5641 - val_loss: 0.6876\n",
            "Epoch 3/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - accuracy: 0.5444 - loss: 0.6922 - val_accuracy: 0.5641 - val_loss: 0.6847\n",
            "Epoch 4/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - accuracy: 0.5197 - loss: 0.6876 - val_accuracy: 0.5641 - val_loss: 0.6841\n",
            "Epoch 5/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.5253 - loss: 0.6922 - val_accuracy: 0.5641 - val_loss: 0.6850\n",
            "Epoch 6/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.5314 - loss: 0.6905 - val_accuracy: 0.5641 - val_loss: 0.6882\n",
            "Epoch 7/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - accuracy: 0.5245 - loss: 0.6935 - val_accuracy: 0.5641 - val_loss: 0.6892\n",
            "Epoch 8/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.5614 - loss: 0.6880 - val_accuracy: 0.5641 - val_loss: 0.6862\n",
            "Epoch 9/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - accuracy: 0.5305 - loss: 0.6869 - val_accuracy: 0.5641 - val_loss: 0.6845\n",
            "Epoch 10/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - accuracy: 0.5283 - loss: 0.6846 - val_accuracy: 0.5641 - val_loss: 0.6870\n",
            "Epoch 11/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - accuracy: 0.5414 - loss: 0.6853 - val_accuracy: 0.5897 - val_loss: 0.6924\n",
            "Epoch 12/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 143ms/step - accuracy: 0.5387 - loss: 0.6843 - val_accuracy: 0.4359 - val_loss: 0.6914\n",
            "Epoch 13/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 157ms/step - accuracy: 0.5535 - loss: 0.6729 - val_accuracy: 0.5641 - val_loss: 0.7003\n",
            "Epoch 14/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 147ms/step - accuracy: 0.6001 - loss: 0.6702 - val_accuracy: 0.4872 - val_loss: 0.7164\n",
            "Epoch 15/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - accuracy: 0.5818 - loss: 0.6783 - val_accuracy: 0.5128 - val_loss: 0.7079\n",
            "Epoch 16/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.5070 - loss: 0.6884 - val_accuracy: 0.4103 - val_loss: 0.7034\n",
            "Epoch 17/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.5205 - loss: 0.6815 - val_accuracy: 0.5641 - val_loss: 0.6998\n",
            "Epoch 18/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.5970 - loss: 0.6779 - val_accuracy: 0.5641 - val_loss: 0.7003\n",
            "Epoch 19/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.5510 - loss: 0.6851 - val_accuracy: 0.5641 - val_loss: 0.7003\n",
            "Epoch 20/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.5558 - loss: 0.6758 - val_accuracy: 0.5128 - val_loss: 0.7021\n",
            "Epoch 21/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.5585 - loss: 0.6998 - val_accuracy: 0.5385 - val_loss: 0.7039\n",
            "Epoch 22/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.5948 - loss: 0.6718 - val_accuracy: 0.5641 - val_loss: 0.7046\n",
            "Epoch 23/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.5440 - loss: 0.6741 - val_accuracy: 0.5641 - val_loss: 0.7091\n",
            "Epoch 24/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.6379 - loss: 0.6556 - val_accuracy: 0.4615 - val_loss: 0.7098\n",
            "Epoch 25/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - accuracy: 0.5949 - loss: 0.6844 - val_accuracy: 0.5128 - val_loss: 0.7058\n",
            "Epoch 26/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - accuracy: 0.5657 - loss: 0.6719 - val_accuracy: 0.5641 - val_loss: 0.7010\n",
            "Epoch 27/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.5454 - loss: 0.6869 - val_accuracy: 0.5641 - val_loss: 0.7003\n",
            "Epoch 28/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.5553 - loss: 0.6755 - val_accuracy: 0.5641 - val_loss: 0.7068\n",
            "Epoch 29/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.6131 - loss: 0.6744 - val_accuracy: 0.5641 - val_loss: 0.7138\n",
            "Epoch 30/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.5732 - loss: 0.6806 - val_accuracy: 0.5385 - val_loss: 0.7155\n",
            "Epoch 31/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.5610 - loss: 0.6801 - val_accuracy: 0.5641 - val_loss: 0.7120\n",
            "Epoch 32/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.5768 - loss: 0.6775 - val_accuracy: 0.4872 - val_loss: 0.7098\n",
            "Epoch 33/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - accuracy: 0.6145 - loss: 0.6759 - val_accuracy: 0.5128 - val_loss: 0.7159\n",
            "Epoch 34/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 136ms/step - accuracy: 0.5089 - loss: 0.6946 - val_accuracy: 0.4615 - val_loss: 0.7152\n",
            "Epoch 35/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 156ms/step - accuracy: 0.6497 - loss: 0.6637 - val_accuracy: 0.4872 - val_loss: 0.7202\n",
            "Epoch 36/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - accuracy: 0.5954 - loss: 0.6780 - val_accuracy: 0.4615 - val_loss: 0.7215\n",
            "Epoch 37/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.6150 - loss: 0.6649 - val_accuracy: 0.4615 - val_loss: 0.7234\n",
            "Epoch 38/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.6162 - loss: 0.6681 - val_accuracy: 0.4359 - val_loss: 0.7215\n",
            "Epoch 39/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 0.5779 - loss: 0.6758 - val_accuracy: 0.4872 - val_loss: 0.7288\n",
            "Epoch 40/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - accuracy: 0.5423 - loss: 0.6827 - val_accuracy: 0.4615 - val_loss: 0.7101\n",
            "Epoch 41/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - accuracy: 0.6184 - loss: 0.6773 - val_accuracy: 0.4872 - val_loss: 0.7083\n",
            "Epoch 42/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.6411 - loss: 0.6757 - val_accuracy: 0.4615 - val_loss: 0.7119\n",
            "Epoch 43/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.6366 - loss: 0.6685 - val_accuracy: 0.4359 - val_loss: 0.7177\n",
            "Epoch 44/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - accuracy: 0.5941 - loss: 0.6838 - val_accuracy: 0.4872 - val_loss: 0.7199\n",
            "Epoch 45/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step - accuracy: 0.6145 - loss: 0.6704 - val_accuracy: 0.4615 - val_loss: 0.7304\n",
            "Epoch 46/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 143ms/step - accuracy: 0.6484 - loss: 0.6628 - val_accuracy: 0.4103 - val_loss: 0.7378\n",
            "Epoch 47/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step - accuracy: 0.5898 - loss: 0.6866 - val_accuracy: 0.4615 - val_loss: 0.7195\n",
            "Epoch 48/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 138ms/step - accuracy: 0.6154 - loss: 0.6637 - val_accuracy: 0.4872 - val_loss: 0.7146\n",
            "Epoch 49/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - accuracy: 0.5624 - loss: 0.6841 - val_accuracy: 0.4872 - val_loss: 0.7129\n",
            "Epoch 50/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 144ms/step - accuracy: 0.5763 - loss: 0.6864 - val_accuracy: 0.4615 - val_loss: 0.7200\n",
            "Epoch 51/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 191ms/step - accuracy: 0.5793 - loss: 0.6768 - val_accuracy: 0.4615 - val_loss: 0.7166\n",
            "Epoch 52/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 162ms/step - accuracy: 0.5672 - loss: 0.6863 - val_accuracy: 0.4615 - val_loss: 0.7243\n",
            "Epoch 53/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 156ms/step - accuracy: 0.6123 - loss: 0.6613 - val_accuracy: 0.4615 - val_loss: 0.7387\n",
            "Epoch 54/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - accuracy: 0.5685 - loss: 0.6735 - val_accuracy: 0.4615 - val_loss: 0.7419\n",
            "Epoch 55/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.5928 - loss: 0.6676 - val_accuracy: 0.3590 - val_loss: 0.7553\n",
            "Epoch 56/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - accuracy: 0.5878 - loss: 0.6682 - val_accuracy: 0.4872 - val_loss: 0.7028\n",
            "Epoch 57/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.5836 - loss: 0.6619 - val_accuracy: 0.4872 - val_loss: 0.7045\n",
            "Epoch 58/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - accuracy: 0.5662 - loss: 0.6825 - val_accuracy: 0.4615 - val_loss: 0.7126\n",
            "Epoch 59/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - accuracy: 0.5871 - loss: 0.6654 - val_accuracy: 0.4615 - val_loss: 0.7284\n",
            "Epoch 60/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.5811 - loss: 0.6734 - val_accuracy: 0.4615 - val_loss: 0.7382\n",
            "Epoch 61/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.6349 - loss: 0.6548 - val_accuracy: 0.4615 - val_loss: 0.7144\n",
            "Epoch 62/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - accuracy: 0.5736 - loss: 0.6675 - val_accuracy: 0.5385 - val_loss: 0.7004\n",
            "Epoch 63/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.5571 - loss: 0.6751 - val_accuracy: 0.3846 - val_loss: 0.7117\n",
            "Epoch 64/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - accuracy: 0.6058 - loss: 0.6526 - val_accuracy: 0.3590 - val_loss: 0.7594\n",
            "Epoch 65/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.5733 - loss: 0.6740 - val_accuracy: 0.4615 - val_loss: 0.7096\n",
            "Epoch 66/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - accuracy: 0.6075 - loss: 0.6669 - val_accuracy: 0.4872 - val_loss: 0.7109\n",
            "Epoch 67/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.6424 - loss: 0.6511 - val_accuracy: 0.3846 - val_loss: 0.7635\n",
            "Epoch 68/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - accuracy: 0.6105 - loss: 0.6592 - val_accuracy: 0.4359 - val_loss: 0.7569\n",
            "Epoch 69/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.6128 - loss: 0.6760 - val_accuracy: 0.5385 - val_loss: 0.7087\n",
            "Epoch 70/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - accuracy: 0.5303 - loss: 0.6892 - val_accuracy: 0.5897 - val_loss: 0.6958\n",
            "Epoch 71/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - accuracy: 0.6037 - loss: 0.6645 - val_accuracy: 0.5385 - val_loss: 0.7027\n",
            "Epoch 72/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 135ms/step - accuracy: 0.5923 - loss: 0.6628 - val_accuracy: 0.5385 - val_loss: 0.7110\n",
            "Epoch 73/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - accuracy: 0.5671 - loss: 0.6515 - val_accuracy: 0.4103 - val_loss: 0.7370\n",
            "Epoch 74/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 146ms/step - accuracy: 0.5458 - loss: 0.6564 - val_accuracy: 0.4359 - val_loss: 0.7433\n",
            "Epoch 75/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - accuracy: 0.6488 - loss: 0.6329 - val_accuracy: 0.4103 - val_loss: 0.7464\n",
            "Epoch 76/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.5572 - loss: 0.6712 - val_accuracy: 0.4615 - val_loss: 0.7145\n",
            "Epoch 77/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - accuracy: 0.6162 - loss: 0.6501 - val_accuracy: 0.5128 - val_loss: 0.7176\n",
            "Epoch 78/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - accuracy: 0.6362 - loss: 0.6412 - val_accuracy: 0.4359 - val_loss: 0.7352\n",
            "Epoch 79/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.5489 - loss: 0.6691 - val_accuracy: 0.4615 - val_loss: 0.7337\n",
            "Epoch 80/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - accuracy: 0.6179 - loss: 0.6504 - val_accuracy: 0.5128 - val_loss: 0.7358\n",
            "Epoch 81/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.6166 - loss: 0.6384 - val_accuracy: 0.3846 - val_loss: 0.7689\n",
            "Epoch 82/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - accuracy: 0.6150 - loss: 0.6608 - val_accuracy: 0.4359 - val_loss: 0.7522\n",
            "Epoch 83/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - accuracy: 0.6159 - loss: 0.6600 - val_accuracy: 0.4872 - val_loss: 0.7388\n",
            "Epoch 84/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - accuracy: 0.5971 - loss: 0.6611 - val_accuracy: 0.5128 - val_loss: 0.7535\n",
            "Epoch 85/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 0.5932 - loss: 0.6576 - val_accuracy: 0.3590 - val_loss: 0.7671\n",
            "Epoch 86/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - accuracy: 0.5853 - loss: 0.6752 - val_accuracy: 0.4103 - val_loss: 0.7583\n",
            "Epoch 87/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - accuracy: 0.6290 - loss: 0.6480 - val_accuracy: 0.5128 - val_loss: 0.7352\n",
            "Epoch 88/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.6658 - loss: 0.6459 - val_accuracy: 0.5641 - val_loss: 0.7138\n",
            "Epoch 89/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - accuracy: 0.5988 - loss: 0.6449 - val_accuracy: 0.5385 - val_loss: 0.7096\n",
            "Epoch 90/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - accuracy: 0.5641 - loss: 0.6626 - val_accuracy: 0.5385 - val_loss: 0.7332\n",
            "Epoch 91/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - accuracy: 0.5389 - loss: 0.6619 - val_accuracy: 0.4359 - val_loss: 0.7556\n",
            "Epoch 92/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 154ms/step - accuracy: 0.6144 - loss: 0.6246 - val_accuracy: 0.4872 - val_loss: 0.7610\n",
            "Epoch 93/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - accuracy: 0.5646 - loss: 0.6607 - val_accuracy: 0.4359 - val_loss: 0.7472\n",
            "Epoch 94/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - accuracy: 0.5924 - loss: 0.6545 - val_accuracy: 0.5385 - val_loss: 0.7407\n",
            "Epoch 95/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - accuracy: 0.6548 - loss: 0.6180 - val_accuracy: 0.5128 - val_loss: 0.7474\n",
            "Epoch 96/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - accuracy: 0.5901 - loss: 0.6431 - val_accuracy: 0.4615 - val_loss: 0.7604\n",
            "Epoch 97/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.5663 - loss: 0.6719 - val_accuracy: 0.4359 - val_loss: 0.7598\n",
            "Epoch 98/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - accuracy: 0.5606 - loss: 0.6515 - val_accuracy: 0.4103 - val_loss: 0.7865\n",
            "Epoch 99/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.5937 - loss: 0.6464 - val_accuracy: 0.4103 - val_loss: 0.7904\n",
            "Epoch 100/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - accuracy: 0.5858 - loss: 0.6486 - val_accuracy: 0.4103 - val_loss: 0.7917\n",
            "TSLA - Test accuracy: 0.4103\n",
            "Saved model for TSLA to /content/model_TSLA.h5\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import logging\n",
        "import os\n",
        "\n",
        "# Assuming logger from Segment 2\n",
        "logger.info(\"Starting LSTM training\")\n",
        "\n",
        "def train_lstm_models(lstm_data, epochs=100, batch_size=32):\n",
        "    \"\"\"Train LSTM models for each company.\"\"\"\n",
        "    models = {}\n",
        "\n",
        "    for company, X, y in lstm_data:\n",
        "        logger.info(f\"Training LSTM for {company}\")\n",
        "        print(f\"Training LSTM for {company}\")\n",
        "\n",
        "        # Split data\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            X, y, test_size=0.2, random_state=42\n",
        "        )\n",
        "        logger.info(f\"{company} - Train: {X_train.shape}, Test: {X_test.shape}\")\n",
        "        print(f\"{company} - Train: {X_train.shape}, Test: {X_test.shape}\")\n",
        "\n",
        "        # Build LSTM model\n",
        "        model = Sequential([\n",
        "            LSTM(50, return_sequences=True, input_shape=(X.shape[1], X.shape[2])),\n",
        "            Dropout(0.2),\n",
        "            LSTM(50),\n",
        "            Dropout(0.2),\n",
        "            Dense(25, activation='relu'),\n",
        "            Dense(1, activation='sigmoid')\n",
        "        ])\n",
        "\n",
        "        # Compile model\n",
        "        model.compile(\n",
        "            optimizer='adam',\n",
        "            loss='binary_crossentropy',\n",
        "            metrics=['accuracy']\n",
        "        )\n",
        "\n",
        "        # Train model\n",
        "        history = model.fit(\n",
        "            X_train, y_train,\n",
        "            epochs=epochs,\n",
        "            batch_size=batch_size,\n",
        "            validation_data=(X_test, y_test),\n",
        "            verbose=1\n",
        "        )\n",
        "\n",
        "        # Evaluate model\n",
        "        loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "        logger.info(f\"{company} - Test accuracy: {accuracy:.4f}\")\n",
        "        print(f\"{company} - Test accuracy: {accuracy:.4f}\")\n",
        "\n",
        "        # Save model\n",
        "        model_path = f\"/content/model_{company}.h5\"\n",
        "        model.save(model_path)\n",
        "        logger.info(f\"Saved model for {company} to {model_path}\")\n",
        "        print(f\"Saved model for {company} to {model_path}\")\n",
        "\n",
        "        models[company] = model\n",
        "\n",
        "    return models\n",
        "\n",
        "# Train models using Segment 6 output\n",
        "models = train_lstm_models(lstm_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzqzM7PUEy8f",
        "outputId": "458e9648-bf07-4296-eb1d-ba946248e445"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded model for AAPL\n",
            "Loaded model for MSFT\n",
            "Loaded model for GOOGL\n",
            "Loaded model for TSLA\n",
            "Predicting trends for AAPL\n",
            "Predicted 10 trends for AAPL\n",
            "Predicting trends for MSFT\n",
            "Predicted 10 trends for MSFT\n",
            "Predicting trends for GOOGL\n",
            "Predicted 10 trends for GOOGL\n",
            "Predicting trends for TSLA\n",
            "Predicted 10 trends for TSLA\n",
            "Saved predictions to /content/predictions.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import logging\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Assuming logger, sectors from Segment 2\n",
        "logger.info(\"Starting trend predictions\")\n",
        "\n",
        "def predict_trends(lstm_data, models, forecast_days=10):\n",
        "    \"\"\"Predict stock trends using trained LSTM models.\"\"\"\n",
        "    predictions = []\n",
        "\n",
        "    for company, X, _ in lstm_data:\n",
        "        logger.info(f\"Predicting trends for {company}\")\n",
        "        print(f\"Predicting trends for {company}\")\n",
        "\n",
        "        if company not in models:\n",
        "            logger.warning(f\"No model found for {company}\")\n",
        "            print(f\"No model found for {company}\")\n",
        "            continue\n",
        "\n",
        "        model = models[company]\n",
        "        # Use latest 60-day sequence for prediction\n",
        "        latest_sequence = X[-1:]  # Shape: [1, 60, 3]\n",
        "\n",
        "        # Predict for next forecast_days\n",
        "        company_predictions = []\n",
        "        current_sequence = latest_sequence.copy()\n",
        "        last_date = datetime.strptime(\"2025-04-16\", \"%Y-%m-%d\")  # Latest stock date\n",
        "\n",
        "        for day in range(forecast_days):\n",
        "            # Predict probability\n",
        "            pred_prob = model.predict(current_sequence, verbose=0)[0][0]\n",
        "            trend = 1 if pred_prob >= 0.5 else 0  # Threshold at 0.5\n",
        "            pred_date = last_date + timedelta(days=day + 1)\n",
        "\n",
        "            company_predictions.append({\n",
        "                'company': company,\n",
        "                'date': pred_date.strftime(\"%Y-%m-%d\"),\n",
        "                'trend': trend,\n",
        "                'probability': float(pred_prob)\n",
        "            })\n",
        "\n",
        "            # Update sequence (shift and append dummy data for demo)\n",
        "            # In practice, use actual new data if available\n",
        "            new_data = current_sequence[:, -1, :].copy()\n",
        "            new_data[:, 0] = new_data[:, 0]  # Keep last close (dummy)\n",
        "            new_data[:, 1] = 0.0  # Neutral sentiment\n",
        "            new_data[:, 2] = 0  # No posts\n",
        "            current_sequence = np.append(current_sequence[:, 1:, :], [new_data], axis=1)\n",
        "\n",
        "        predictions.extend(company_predictions)\n",
        "        logger.info(f\"Predicted {len(company_predictions)} trends for {company}\")\n",
        "        print(f\"Predicted {len(company_predictions)} trends for {company}\")\n",
        "\n",
        "    # Save predictions\n",
        "    predictions_df = pd.DataFrame(predictions)\n",
        "    output_path = \"/content/predictions.csv\"\n",
        "    predictions_df.to_csv(output_path, index=False)\n",
        "    logger.info(f\"Saved predictions to {output_path}\")\n",
        "    print(f\"Saved predictions to {output_path}\")\n",
        "\n",
        "    return predictions_df\n",
        "\n",
        "# Load models\n",
        "models = {}\n",
        "for company in ['AAPL', 'MSFT', 'GOOGL', 'TSLA']:\n",
        "    model_path = f\"/content/model_{company}.h5\"\n",
        "    if os.path.exists(model_path):\n",
        "        models[company] = tf.keras.models.load_model(model_path)\n",
        "        print(f\"Loaded model for {company}\")\n",
        "    else:\n",
        "        print(f\"Model not found for {company}\")\n",
        "\n",
        "# Predict trends using Segment 6's lstm_data\n",
        "predictions_df = predict_trends(lstm_data, models)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IX3Q6vPeE3J7",
        "outputId": "adeb03aa-9be6-4a93-aea9-487365e1c314"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded predictions: 40 rows\n",
            "Generated 30 alerts, saved to /content/alerts.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import logging\n",
        "\n",
        "# Assuming logger from Segment 2\n",
        "logger.info(\"Starting alert generation\")\n",
        "\n",
        "def generate_alerts(predictions_file='/content/predictions.csv'):\n",
        "    try:\n",
        "        predictions = pd.read_csv(predictions_file)\n",
        "        logger.info(f\"Loaded predictions: {len(predictions)} rows\")\n",
        "        print(f\"Loaded predictions: {len(predictions)} rows\")\n",
        "\n",
        "        alerts = []\n",
        "        for _, row in predictions.iterrows():\n",
        "            probability = row['probability']\n",
        "            trend = row['trend']\n",
        "            if probability >= 0.7 and trend == 1:\n",
        "                alert_type = 'Strong Buy'\n",
        "                alerts.append({\n",
        "                    'company': row['company'],\n",
        "                    'date': row['date'],\n",
        "                    'alert_type': alert_type,\n",
        "                    'probability': probability\n",
        "                })\n",
        "            elif probability <= 0.3 and trend == 0:\n",
        "                alert_type = 'Strong Sell'\n",
        "                alerts.append({\n",
        "                    'company': row['company'],\n",
        "                    'date': row['date'],\n",
        "                    'alert_type': alert_type,\n",
        "                    'probability': probability\n",
        "                })\n",
        "\n",
        "        alerts_df = pd.DataFrame(alerts)\n",
        "        alerts_df.to_csv('/content/alerts.csv', index=False)\n",
        "        logger.info(f\"Generated {len(alerts)} alerts, saved to /content/alerts.csv\")\n",
        "        print(f\"Generated {len(alerts)} alerts, saved to /content/alerts.csv\")\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Alert generation failed: {e}\")\n",
        "        print(f\"Alert generation failed: {e}\")\n",
        "\n",
        "generate_alerts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IaOzqWi2GvF2",
        "outputId": "1c1f7b1c-9301-4c73-9ffe-b471b682a76c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.11/dist-packages (1.43.2)\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.11/dist-packages (7.2.3)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (5.24.1)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.1.8)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.1.0)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.4)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (16.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.1.2)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.13.2)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.35.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.1.31)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.24.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install streamlit pyngrok plotly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Af9BhxtEG4Y1",
        "outputId": "546bfe94-3bf2-40fd-eb0a-fedbd1d31fb7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": []
        }
      ],
      "source": [
        "from pyngrok import ngrok\n",
        "ngrok.set_auth_token(\"2tXLBQHCEqsQS0TYDRNHF5w8fHk_2rbtDMMHkdDsLPdss1hUP\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AieYxh3mHHIS",
        "outputId": "aee611a0-0b7b-41a9-a786-1e93748cddbd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-04-19 07:56:45.240 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-19 07:56:45.244 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\n"
          ]
        }
      ],
      "source": [
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import logging\n",
        "import os\n",
        "\n",
        "# Configure Streamlit page\n",
        "st.set_page_config(\n",
        "    page_title=\"Stock Sentiment Dashboard\",\n",
        "    layout=\"wide\",\n",
        "    initial_sidebar_state=\"expanded\"\n",
        ")\n",
        "\n",
        "# Logger setup\n",
        "logging.basicConfig(\n",
        "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
        "    level=logging.INFO\n",
        ")\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Define CSV paths\n",
        "PRED_PATH = os.path.abspath('/content/predictions.csv')\n",
        "ALERTS_PATH = os.path.abspath('/content/alerts.csv')\n",
        "\n",
        "@st.cache_data(show_spinner=True)\n",
        "def load_data():\n",
        "    \"\"\"\n",
        "    Load predictions and alerts. Alerts failures are non-fatal.\n",
        "    Returns: df (DataFrame or None), alerts (DataFrame or empty)\n",
        "    \"\"\"\n",
        "    # Load predictions (fatal if fails)\n",
        "    try:\n",
        "        logger.info(f\"Loading predictions from {PRED_PATH}\")\n",
        "        df = pd.read_csv(PRED_PATH, parse_dates=['date'])\n",
        "        logger.info(f\"Loaded {len(df)} prediction rows\")\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error loading predictions: {e}\")\n",
        "        return None, None\n",
        "\n",
        "    # Load alerts (non-fatal)\n",
        "    try:\n",
        "        logger.info(f\"Loading alerts from {ALERTS_PATH}\")\n",
        "        alerts = pd.read_csv(ALERTS_PATH, parse_dates=['date'])\n",
        "        logger.info(f\"Loaded {len(alerts)} alert rows\")\n",
        "    except Exception as e:\n",
        "        alerts = pd.DataFrame()\n",
        "        logger.warning(f\"Unable to load alerts: {e} -- continuing without alerts\")\n",
        "\n",
        "    return df, alerts\n",
        "\n",
        "# Write out the dashboard script (dashboard.py)\n",
        "script_lines = [\n",
        "    'import streamlit as st',\n",
        "    'import pandas as pd',\n",
        "    'import plotly.express as px',\n",
        "    'import logging',\n",
        "    'import os',\n",
        "    '',\n",
        "    \"st.set_page_config(page_title='Stock Sentiment Dashboard', layout='wide')\",\n",
        "    '',\n",
        "    \"logging.basicConfig(format='%(asctime)s - %(levelname)s - %(message)s', level=logging.INFO)\",\n",
        "    \"logger = logging.getLogger(__name__)\",\n",
        "    '',\n",
        "    f\"PRED_PATH = r'{PRED_PATH}'\",\n",
        "    f\"ALERTS_PATH = r'{ALERTS_PATH}'\",\n",
        "    '',\n",
        "    \"@st.cache_data(show_spinner=True)\",\n",
        "    \"def load_data():\",\n",
        "    \"    try:\",\n",
        "    \"        df = pd.read_csv(PRED_PATH, parse_dates=['date'])\",\n",
        "    \"    except Exception as e:\",\n",
        "    \"        st.error(f'Error loading predictions: {e}')\",\n",
        "    \"        return None, None\",\n",
        "    \"    try:\",\n",
        "    \"        alerts = pd.read_csv(ALERTS_PATH, parse_dates=['date'])\",\n",
        "    \"    except Exception as e:\",\n",
        "    \"        alerts = pd.DataFrame()\",\n",
        "    \"        st.warning(f'Unable to load alerts: {e} - proceeding without alerts')\",\n",
        "    \"    return df, alerts\",\n",
        "    '',\n",
        "    \"# Main app\",\n",
        "    \"st.title('📈 Stock Sentiment Dashboard')\",\n",
        "    \"df, alerts = load_data()\",\n",
        "    \"if df is None:\",\n",
        "    \"    st.error('Failed to load predictions. Check file path and format.')\",\n",
        "    \"else:\",\n",
        "    \"    st.write(f'Loaded predictions: {len(df)} rows')\",\n",
        "    \"    if not alerts.empty:\",\n",
        "    \"        st.write(f'Loaded alerts: {len(alerts)} rows')\",\n",
        "    \"    else:\",\n",
        "    \"        st.info('No alerts available or failed to load alerts.')\",\n",
        "    \"    # Company selector\",\n",
        "    \"    companies = df['company'].unique().tolist()\",\n",
        "    \"    selected_company = st.sidebar.selectbox('Select Company', companies)\",\n",
        "    \"    subdf = df[df['company'] == selected_company]\",\n",
        "    \"    fig = px.line(subdf, x='date', y='probability', title=f'Trend Probability for {selected_company}', labels={'probability':'Probability','date':'Date'})\",\n",
        "    \"    st.plotly_chart(fig, use_container_width=True)\",\n",
        "    \"    # Alerts display\",\n",
        "    \"    if not alerts.empty:\",\n",
        "    \"        comp_alerts = alerts[alerts['company'] == selected_company]\",\n",
        "    \"        if not comp_alerts.empty:\",\n",
        "    \"            st.subheader(f'Alerts for {selected_company}')\",\n",
        "    \"            st.dataframe(comp_alerts[['date','alert_type','probability']])\",\n",
        "    \"        else:\",\n",
        "    \"            st.write('No alerts for this company.')\",\n",
        "]\n",
        "with open('dashboard.py', 'w') as fh:\n",
        "    fh.write(\"\\n\".join(script_lines))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tpvRvJgKFOzJ",
        "outputId": "3db65cc4-a987-4d41-80ce-49da8830523d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Streamlit dashboard running at: NgrokTunnel: \"https://e3c3-35-239-177-220.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ],
      "source": [
        "from pyngrok import ngrok\n",
        "import subprocess\n",
        "import time\n",
        "\n",
        "# Start Streamlit\n",
        "streamlit_proc = subprocess.Popen([\"streamlit\", \"run\", \"/content/dashboard.py\", \"--server.port\", \"8501\"])\n",
        "time.sleep(5)  # Wait for Streamlit to start\n",
        "public_url = ngrok.connect(8501)\n",
        "print(f\"Streamlit dashboard running at: {public_url}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_JH5B0PYvxJc",
        "outputId": "8e300594-58a6-4ee9-ec75-a65d37d8ccb2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded predictions: 40 rows\n",
            "\n",
            "Predictions DataFrame:\n",
            "company       date  trend  probability\n",
            "   AAPL 2025-04-17      0     0.491132\n",
            "   AAPL 2025-04-18      0     0.490191\n",
            "   AAPL 2025-04-19      0     0.490738\n",
            "   AAPL 2025-04-20      0     0.492767\n",
            "   AAPL 2025-04-21      0     0.496155\n",
            "   AAPL 2025-04-22      1     0.500915\n",
            "   AAPL 2025-04-23      1     0.506820\n",
            "   AAPL 2025-04-24      1     0.513527\n",
            "   AAPL 2025-04-25      1     0.520711\n",
            "   AAPL 2025-04-26      1     0.528968\n",
            "   MSFT 2025-04-17      0     0.074227\n",
            "   MSFT 2025-04-18      0     0.077494\n",
            "   MSFT 2025-04-19      0     0.079625\n",
            "   MSFT 2025-04-20      0     0.083903\n",
            "   MSFT 2025-04-21      0     0.088665\n",
            "   MSFT 2025-04-22      0     0.100714\n",
            "   MSFT 2025-04-23      0     0.107225\n",
            "   MSFT 2025-04-24      0     0.122982\n",
            "   MSFT 2025-04-25      0     0.129164\n",
            "   MSFT 2025-04-26      0     0.138835\n",
            "  GOOGL 2025-04-17      0     0.250819\n",
            "  GOOGL 2025-04-18      0     0.251715\n",
            "  GOOGL 2025-04-19      0     0.253206\n",
            "  GOOGL 2025-04-20      0     0.254755\n",
            "  GOOGL 2025-04-21      0     0.257296\n",
            "  GOOGL 2025-04-22      0     0.259814\n",
            "  GOOGL 2025-04-23      0     0.263119\n",
            "  GOOGL 2025-04-24      0     0.267256\n",
            "  GOOGL 2025-04-25      0     0.271344\n",
            "  GOOGL 2025-04-26      0     0.275818\n",
            "   TSLA 2025-04-17      0     0.098343\n",
            "   TSLA 2025-04-18      0     0.088787\n",
            "   TSLA 2025-04-19      0     0.079251\n",
            "   TSLA 2025-04-20      0     0.069323\n",
            "   TSLA 2025-04-21      0     0.065812\n",
            "   TSLA 2025-04-22      0     0.059653\n",
            "   TSLA 2025-04-23      0     0.056883\n",
            "   TSLA 2025-04-24      0     0.055807\n",
            "   TSLA 2025-04-25      0     0.054990\n",
            "   TSLA 2025-04-26      0     0.055094\n",
            "Loaded alerts: 30 rows\n",
            "Saved predictions table for AAPL\n",
            "Saved probability plot for AAPL\n",
            "Saved predictions table for MSFT\n",
            "Saved probability plot for MSFT\n",
            "Saved predictions table for GOOGL\n",
            "Saved probability plot for GOOGL\n",
            "Saved predictions table for TSLA\n",
            "Saved probability plot for TSLA\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "import logging\n",
        "\n",
        "# Assuming logger from Segment 2\n",
        "logger.info(\"Starting local plotting dashboard\")\n",
        "\n",
        "# Set Seaborn style\n",
        "sns.set_theme(style=\"darkgrid\")\n",
        "sns.set_palette(\"deep\")\n",
        "\n",
        "def plot_dashboard(predictions_file=\"/content/predictions.csv\", alerts_file=\"/content/alerts.csv\"):\n",
        "    \"\"\"Plot predictions locally using Matplotlib and Seaborn, skip alerts if invalid.\"\"\"\n",
        "    # Check if predictions file exists\n",
        "    if not os.path.exists(predictions_file):\n",
        "        logger.error(f\"Predictions file not found: {predictions_file}\")\n",
        "        print(f\"Predictions file not found: {predictions_file}\")\n",
        "        return\n",
        "\n",
        "    # Load predictions\n",
        "    try:\n",
        "        predictions = pd.read_csv(predictions_file)\n",
        "        if predictions.empty or not all(col in predictions for col in ['company', 'date', 'trend', 'probability']):\n",
        "            raise ValueError(\"Predictions CSV is empty or missing required columns\")\n",
        "        logger.info(f\"Loaded predictions: {len(predictions)} rows\")\n",
        "        print(f\"Loaded predictions: {len(predictions)} rows\")\n",
        "        # Print predictions DataFrame\n",
        "        print(\"\\nPredictions DataFrame:\")\n",
        "        print(predictions[['company', 'date', 'trend', 'probability']].to_string(index=False))\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Failed to load predictions: {e}\")\n",
        "        print(f\"Failed to load predictions: {e}\")\n",
        "        return\n",
        "\n",
        "    # Load alerts (allow failure)\n",
        "    alerts = pd.DataFrame(columns=['company', 'date', 'alert_type', 'probability'])\n",
        "    try:\n",
        "        alerts_temp = pd.read_csv(alerts_file)\n",
        "        if not alerts_temp.empty and all(col in alerts_temp for col in ['company', 'date', 'alert_type', 'probability']):\n",
        "            alerts = alerts_temp\n",
        "            logger.info(f\"Loaded alerts: {len(alerts)} rows\")\n",
        "            print(f\"Loaded alerts: {len(alerts)} rows\")\n",
        "        else:\n",
        "            logger.warning(\"Alerts CSV is empty or has invalid columns, skipping alerts plotting\")\n",
        "            print(\"Alerts CSV is empty or has invalid columns, skipping alerts plotting\")\n",
        "            print(\"Plotting predictions only\")\n",
        "    except Exception as e:\n",
        "        logger.warning(f\"Failed to load alerts: {e}, skipping alerts plotting\")\n",
        "        print(f\"Failed to load alerts: {e}, skipping alerts plotting\")\n",
        "        print(\"Plotting predictions only\")\n",
        "\n",
        "    # Create output directory\n",
        "    os.makedirs(\"/content/plots\", exist_ok=True)\n",
        "\n",
        "    # Plot for each company\n",
        "    companies = predictions['company'].unique()\n",
        "    for company in companies:\n",
        "        # Filter data\n",
        "        company_predictions = predictions[predictions['company'] == company]\n",
        "\n",
        "        # Plot 1: Predictions Table\n",
        "        fig, ax = plt.subplots(figsize=(8, 4))\n",
        "        ax.axis('off')\n",
        "        table_data = company_predictions[['date', 'trend', 'probability']].round(3)\n",
        "        table = ax.table(cellText=table_data.values, colLabels=table_data.columns, loc='center', cellLoc='center')\n",
        "        table.auto_set_font_size(False)\n",
        "        table.set_fontsize(10)\n",
        "        table.scale(1.2, 1.2)\n",
        "        plt.title(f\"Predictions for {company}\", pad=20)\n",
        "        plt.savefig(f\"/content/plots/{company}_predictions.png\", bbox_inches='tight', dpi=300)\n",
        "        plt.close()\n",
        "        logger.info(f\"Saved predictions table for {company}\")\n",
        "        print(f\"Saved predictions table for {company}\")\n",
        "\n",
        "        # Plot 2: Probability Line Plot\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        sns.lineplot(data=company_predictions, x='date', y='probability', marker='o')\n",
        "        plt.title(f\"Trend Probability for {company}\")\n",
        "        plt.xlabel(\"Date\")\n",
        "        plt.ylabel(\"Trend Probability\")\n",
        "        plt.xticks(rotation=45)\n",
        "        plt.grid(True)\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f\"/content/plots/{company}_probability.png\", bbox_inches='tight', dpi=300)\n",
        "        plt.close()\n",
        "        logger.info(f\"Saved probability plot for {company}\")\n",
        "        print(f\"Saved probability plot for {company}\")\n",
        "\n",
        "# Run plotting\n",
        "plot_dashboard()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mMU0TwNBHmO2",
        "outputId": "fd42f688-5ea3-494d-f3f6-94f9a0aa8034"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/dashboard.py\n",
            "import streamlit as st\n",
            "import pandas as pd\n",
            "import plotly.express as px\n",
            "import logging\n",
            "import os\n",
            "\n",
            "st.set_page_config(page_title='Stock Sentiment Dashboard', layout='wide')\n",
            "\n",
            "logging.basicConfig(format='%(asctime)s - %(levelname)s - %(message)s', level=logging.INFO)\n",
            "logger = logging.getLogger(__name__)\n"
          ]
        }
      ],
      "source": [
        "!ls /content/dashboard.py\n",
        "!head -n 10 /content/dashboard.py"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}